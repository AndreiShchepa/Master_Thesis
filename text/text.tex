
% uncomment the following line to create an unnumbered chapter
\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}\markboth{Introduction}{Introduction}
%---------------------------------------------------------------
\setcounter{page}{1}

% Problem, motivation, goal, contributions, and thesis roadmap.
% Why smart contract bugs are high impact (immutability, financial incentives) and why existing audits/tools still miss logical flaws. Tell about security audits and how it is time consuming. Then a bit about LLM, which is developed in parallel.
% State your contribution precisely: extending Wake-AI with MCP-based RAG + building KB from Solidity vulns/audit knowledge.
% One paragraph explaining what each chapter delivers and how it connects. (ethereum, code analysis, large language models, wake framework, proposes methododology, implementation, evaluation, conclusion)

In June 2016, an attacker exploited a reentrancy vulnerability in The DAO smart contract, draining approximately \$60 million worth of Ether in a matter of hours\footnote{\url{https://www.gemini.com/cryptopedia/the-dao-hack-makerdao}}. This incident, along with numerous subsequent exploits in decentralized finance (DeFi) protocols, highlights a fundamental challenge in blockchain development: once deployed, smart contracts are immutable, and vulnerabilities cannot be easily patched. Unlike traditional software where bugs might cause inconvenience or data corruption, smart contract vulnerabilities directly translate to financial losses, often measured in millions of dollars.

% The immutability of blockchain systems creates a paradox for security. While immutability is precisely what makes smart contracts trustworthy—users can verify that contract logic won't change arbitrarily—it also means that any security flaw becomes permanent. An attacker who discovers a vulnerability can exploit it with confidence, knowing the code cannot be modified to prevent the attack. Moreover, the financial nature of most smart contract applications creates strong economic incentives for exploitation. When a DeFi protocol manages hundreds of millions in assets, even sophisticated attackers invest significant resources in finding vulnerabilities. This high-stakes environment has driven the development of increasingly rigorous security audit practices, yet critical vulnerabilities continue to slip through.

Current smart contract security is highly dependent on manual code audits supplemented by automated analysis tools. Professional audit firms employ expert security researchers who spend weeks examining contract code, looking for common vulnerability patterns, reasoning about edge cases, and trying to violate protocol invariants \cite{perez2021smart}. 

% The fundamental limitation is that many critical vulnerabilities are not simple pattern matches but rather logical flaws that emerge from complex interactions between contract components or violations of implicit business logic assumptions. For example, a flash loan attack might exploit the interaction between a pricing oracle, a lending pool, and a liquidation mechanism in ways that are individually correct but collectively create arbitrage opportunities. Detecting such vulnerabilities requires understanding not just what the code does syntactically, but what it means semantically in the context of the broader protocol design. This type of reasoning has historically required human expertise, making audits time-consuming and expensive—typically taking 2-4 weeks and costing \$50,000-\$200,000 for a medium-sized protocol \cite{consensys2023audit}.

Recent advances in Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and reasoning about code. Models trained on vast corpora of source code, like GPT-4 \cite{openai2023gpt4} and Claude \cite{anthropic2024claude}, can explain code functionality, identify potential bugs, and even generate secure implementations when properly prompted. However, applying LLMs directly to smart contract security faces several challenges. First, LLMs have limited context windows—even models with 200,000 token contexts cannot process entire DeFi protocols with their complex interdependencies and imported libraries. Second, LLMs lack access to the structured analysis results produced by static analysis tools, which provide precise information about control flow, data dependencies, and detected patterns. Third, effective vulnerability analysis requires domain-specific knowledge about Solidity-specific pitfalls, common attack vectors, and audit best practices that may not be well-represented in general code training data.

This thesis addresses these challenges by developing an integrated system that combines the static analysis capabilities of the Wake framework with the reasoning abilities of LLMs through a Model Context Protocol (MCP)-based architecture. Wake is an advanced Python-based framework for Solidity analysis that provides rich programmatic access to abstract syntax trees, control flow graphs, and custom vulnerability detectors \cite{wake2023documentation}. By augmenting Wake with LLM-based analysis through MCP—a protocol that enables structured tool use by language models—we create a system where the LLM can request specific analysis results, retrieve relevant code segments, and access domain knowledge as needed, rather than requiring all context upfront.

% \section*{Contributions}

% This thesis makes the following contributions:

% \textbf{1. MCP-based RAG Architecture for Code Analysis:} We design and implement a Retrieval-Augmented Generation system that enables LLMs to effectively analyze large smart contract codebases despite context window limitations. Our architecture uses the Model Context Protocol to provide the LLM with structured access to code segments, static analysis results, and domain knowledge. Unlike naive approaches that attempt to fit entire contracts into context, our system allows the LLM to iteratively retrieve relevant information based on its analysis needs, enabling it to handle real-world DeFi protocols that span dozens of contracts and tens of thousands of lines of code.

% \textbf{2. Domain-Specific Knowledge Base:} We construct a curated knowledge base of Solidity vulnerability patterns, audit methodologies, and security best practices drawn from public audit reports, vulnerability databases like the Smart Contract Weakness Classification (SWC), and documentation of historical exploits. This knowledge base is structured to support efficient retrieval and provides the LLM with specialized information about blockchain-specific attack vectors that may not be adequately represented in its pre-training data. We develop embedding strategies and retrieval mechanisms specifically tuned for technical security content.

% \textbf{3. Wake Framework Integration:} We extend the Wake-AI project with MCP server implementations that expose Wake's analysis capabilities to LLM agents. This integration allows the language model to request specific analysis operations—such as computing data flow for a variable, identifying all functions that modify a particular state variable, or retrieving functions that match specific structural patterns—and receive structured results that inform its reasoning. The MCP-based design ensures that the integration remains modular and extensible to additional analysis tools.

% \textbf{4. Empirical Evaluation:} We evaluate our system on a dataset of real smart contracts with known vulnerabilities, measuring both detection accuracy and the quality of vulnerability explanations. Our evaluation examines how effectively the RAG-augmented LLM identifies different vulnerability classes compared to baseline static analyzers and explores the system's ability to explain detected issues in ways useful to human auditors. We also analyze failure modes to understand the limitations of the LLM-based approach.

The first chapter provides the necessary background on blockchain technology, the Ethereum platform, and smart contract development. It also establishes the domain context and security challenges that motivate this work.

The second chapter surveys existing approaches to code analysis like static analysis, dynamic testing and formal verification.

The third chapter explores the application of LLMs to code understanding and security analysis. We explain the transformer architecture that underlies modern language models, discuss how these models are adapted for code through pre-training and fine-tuning, and examine their capabilities and limitations for vulnerability detection. 

The remainder of the chapters focus on the design of the methodology proposed that was described above, its implementation and evaluation.

% \textbf{Chapter 5: Retrieval-Augmented Generation and Tool Use} introduces the key techniques that enable LLMs to work effectively with large codebases and specialized tools. We explain Retrieval-Augmented Generation (RAG) architectures, embedding strategies for code, and the Model Context Protocol that allows LLMs to orchestrate external tools. This chapter provides the conceptual framework for our system design.

% \textbf{Chapter 6: Methodology} presents our approach in detail. We describe the architecture of our MCP-based RAG system, the design of our domain knowledge base, the integration with Wake's analysis capabilities, and the retrieval strategies we employ. This chapter explains the key design decisions and trade-offs in building a practical LLM-augmented audit system.

% \textbf{Chapter 7: Implementation} details the concrete realization of our design. We discuss the software architecture, MCP server implementations, database schemas, and integration points between components. This chapter provides sufficient detail for replication and extension of our work.

% \textbf{Chapter 8: Evaluation} presents our experimental results. We describe our dataset of vulnerable contracts, evaluation metrics, baseline comparisons, and analysis of system performance across different vulnerability classes. We examine both quantitative metrics like precision and recall as well as qualitative aspects like explanation quality and practical utility for auditors.

The last chapter summarizes contributions of this work, discusses limitations and results of the proposed approach, and outlines directions for future work.

The goal of this thesis is not to replace human auditors with automated systems—the creative reasoning and contextual understanding required for comprehensive security analysis remains a fundamentally human capability. Rather, we aim to augment auditors with intelligent tools that handle the mechanical aspects of information retrieval and pattern recognition, allowing human expertise to focus on the complex reasoning tasks where it adds the most value. By combining the precision of static analysis, the knowledge retrieval of RAG systems, and the pattern recognition of LLMs, we take a step toward making smart contract security more accessible and effective.

\chapter*{Objectives}
\label{ch:objetives}
Tell a bit about what was done and list objectives that were fullfilled:

\begin{itemize}
    \item Common vulnerability patterns and existing auditing methodologies of Ethereum smart contracts were studied.
    \item A state of the art review on the integration of Large Language Models for automated reasoning and the development of AI-based auditing agents was conducted.
    \item A system that integrates an LLM into the security auditing workflow was designed with further implementation, testing and evaluation.
    \item The obtained results, limitations, and potential improvements of LLM-based auditing systems were discussed in the end.
\end{itemize}


\chapter{Ethereum}
\label{ch:ethereum}
This chapter introduces the foundations needed to understand Ethereum and its components, as this work is closely related to that platform. It first outlines the general principles of blockchain, then specializes in the Ethereum execution model through the Ethereum Virtual Machine (EVM) and the Solidity programming language. Finally, it summarizes common smart-contract vulnerability categories that repeatedly appear in practical audits.


\section{Overview}
\label{sec:overview}
Ethereum, launched in 2015, marked a significant evolution in blockchain technology. First proposed by \texttt{Vitalik Buterin} in a 2013 white paper, Ethereum extends the ledger-centric model to a full application platform that supports smart contracts and decentralized applications (dApps) \cite{Buterin2013}. Rather than simply recording value transfers, it enables general-purpose programmable logic through the EVM while preserving the core properties of transparency, decentralization,and immutability \cite{wood2014yellow}. In effect, Ethereum transformed the blockchain as a generalized state-transition machine, broadening its applicability well beyond simple currency use cases.


\subsection{Blockchain}
\label{subsec:blockchain}

To understand Ethereum's role as a programmable state-transition system, 
it is useful to begin with the blockchain foundation on which it operates. 
A blockchain is a distributed ledger maintained by a network of 
peer-to-peer nodes rather than a single central authority. It grows as an 
ordered sequence of blocks, beginning with an initial block (commonly 
called the \emph{genesis block}), where each subsequent block contains a 
complete list of transaction records and a cryptographic link to its 
predecessor. As additional blocks are appended, reversing or altering 
earlier transactions becomes computationally infeasible. Participants 
interact through addresses instead of real-world identities, enabling 
transparency while preserving pseudonymity. Because every node stores a 
copy of the chain and the full transaction history is publicly verifiable, 
the system provides strong transparency: value flows can be traced, state 
transitions inspected, and the integrity of past operations independently 
confirmed. In short, from the initial genesis block through every appended 
block, blockchain architecture combines decentralization, tamper-resistance, 
and verifiable history in a single framework \cite{blockchain}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/block_eth.png}
    \caption{Structure of an Ethereum blockchain node \cite{blockchain_diagram_eth}.}
    \label{fig:block_eth}
\end{figure}

As illustrated in Figure~\ref{fig:block_eth}, a blockchain block links to 
its predecessor and successor by storing the cryptographic hash of the 
previous block's header within its own header, forming an immutable and 
ordered chain. Beyond this backward pointer, the block header contains 
four key fields: the \emph{previous block hash}, a \emph{timestamp} 
recording when the block was produced, a \emph{nonce} adjusted during the 
consensus process, and the \emph{Merkle root}, a single hash that 
compactly summarises all transactions contained in the block 
\cite{blockchain_diagram_eth}.

A \emph{transaction} is the fundamental unit of state change in a 
blockchain: a cryptographically signed instruction issued by a participant 
that records the transfer of value or data between addresses. Each 
transaction is broadcast to the network, validated by nodes, and 
permanently written into a block, after which it becomes immutable.

\subsubsection*{Merkle Tree}

The lower portion of Figure~\ref{fig:block_eth} expands the block's 
transaction set into a \emph{Merkle tree}: a binary tree in which each 
leaf holds the cryptographic hash of an individual transaction and each 
internal node holds the hash of its two children's concatenation. Leaf 
hashes are combined pairwise and re-hashed level by level until a single 
\emph{Merkle root} remains. Because every internal node is derived from 
its children, any alteration to a transaction propagates deterministically 
upward, changing the root and invalidating the block header --- making the 
root a binding cryptographic commitment to the entire transaction set 
\cite{merkle1987, nakamoto2008}.

This design enables \emph{inclusion proofs} of size $O(\log n)$: to 
verify that a transaction belongs to a block, a verifier needs only the 
transaction itself, the header's Merkle root, and the minimal set of 
sibling hashes along the path from leaf to root --- not the full block. 
This allows lightweight validation without downloading entire blocks, 
saving bandwidth and storage. Furthermore, the previous-hash pointer in 
each header secures global block ordering: any retroactive modification 
breaks the chain link to all subsequent blocks, making tampering 
immediately detectable by any honest node in the network 
\cite{nakamoto2008, merkle_tree}.


\subsection{Consensus mechanisms}
\label{subsec:consensus}
Once the block structure is established, the network must agree on which block to append next --- a process governed by the \emph{consensus mechanism}, the design of which depends on the blockchain's trust model. Across different deployment models, two dominant consensus families have emerged.

\subsubsection*{Proof of Work}
The first concept/method used by blockchains. Generally, the nodes in a PoW-based blockchain network reach consensus by participating in a solution searching process, where each node must find a nonce for its proposed new block. Due to the property of the hash function, the nonce can only be found by repeatedly trying different nonce values until the output is within the target range. When a participant finds the nonce, it will broadcast the block along with the transactions to other nodes. Then, if the new block is verified and determined to be the first block mined after the last block in the chain, it will be integrated into the current chain and become the latest block in the chain. This solution searching procedure can be considered to be a weighted random coin-tossing process where a participant with a higher hash rate(computational power) might have higher chances to be the block winner (leader) who can receive the reward. his computa-tion leads to the large amount of energy consumption forblockchains using PoW consensus mechanisms, as the par-ticipants try to increase their hash rates to have a higherchance to be the leader and receive rewards. Moreover, sinceparticipants with low hash rates have very low chances towin a block and receive rewards, they often join miningpools to have more opportunities to get revenues. A miningpool consists of participants who want to collaborate by con-tributing their computing resources to the pool. In this way,mining tasks will be distributed to the miners, and due to hugecomputing resources, mining pools often get much higher op-portunities to win a new block than individuals. While joininga mining pool provides more stable incomes, the nodes inthe pool often do not contribute to the transaction validationand propagation since they only perform the nonce searchprocess in a specific range. Thus, mining pools have beendominating processes making new blocks in most of currentblockchain networks. For example, the top five mining poolscontrol up to 62.7\% total hash rate of the Bitcoin network [3].This is the most serious issue of PoW-based blockchainnetworks because it is against the decentralized spirit ofblockchain technology. Another issue of PoW protocols isdelay. In a PoW-based blockchain network, when a block isadded to the chain, there is still a possibility that this blockwill not be included in the main chain for several reasons,e.g., network delay causing several versions of the chainor two participants finding two blocks simultaneously. Thispossibility decreases exponentially as the block is deeper inthe chain. Therefore, a block is considered to be finalizedonly when it is a certain k, usually six blocks deep in thechain. This delays the transaction confirmation significantly.Moreover, PoW mechanism is also vulnerable to 51\% attack.In particular, if a single party controls more than 51\% of thenetwork’s total computational power, they can spend theircoins multiple times (in cryptocurrency networks) or preventother transactions by adding conflicting blocks to the chain.While 51\% attacks might not be a serious problem for largeblockchain networks, the newly established networks withsmall and limited total computational power are especiallyvulnerable 


\subsubsection*{Proof of Stake}
The first Proof-of-Stakes (PoS) network, Peercoin [16], wasdeveloped as a PoX consensus mechanism with the aim toreduce the computational requirements of PoW. Participantswith higher coin age, i.e., product of network tokens and theirholding time, have higher chances to be selected. Specifi-cally, each node in Peercoin solves a PoW puzzle with itsown difficulty, which can be reduced by consuming coin age.In the more recent PoS networks, the solution searching iscompletely removed, and the block leaders are no longerselected by computational power. Instead, they are selectedbased on the stakes that they are holding.With the stake-based leader selection process, a node’schance to be selected to be a leader no longer depends on itscomputational power, and thus energy consumption of PoS mechanisms is significantly reduced compared with that ofPoW. Moreover, the block generation and transaction con-firmation speeds are kept at relatively low constant rates bythe PoW networks to ensure security because there are manydifferent blocks proposed by the miners. In contrast, sinceonly one block is made in each round of PoS mechanisms,the block generation and transaction confirmation speedsare usually much faster, and thus PoS mechanism starts tobecome popular recently. 

PoS (Proof of stake) is an energy-saving alternative to PoW.Miners in PoS have to prove the ownership of the amountof currency. It is believed that people with more currencieswould be less likely to attack the network. The selectionbased on account balance is quite unfair because the singlerichest person is bound to be dominant in the network. As aresult, many solutions are proposed with the combination ofthe stake size to decide which one to forge the next block.In particular, Blackcoin [26] uses randomization to predict thenext generator. It uses a formula that looks for the lowesthash value in combination with the size of the stake. Peercoin[21] favors coin age based selection. In Peercoin, older andlarger sets of coins have a greater probability of mining thenext block. Compared to PoW, PoS saves more energy andis more effective. Unfortunately, as the mining cost is nearlyzero, attacks might come as a consequence. Many blockchainsadopt PoW at the beginning and transform to PoS gradually.For instance, ethereum is planing to move from Ethash ( 





With a solid understanding of how blocks are structured and how consensus mechanisms work, we can turn our attention to the next layer of the architecture: how transactions and smart contract code are actually executed.

\section{Ethereum Virtual Machine}
The Ethereum Virtual Machine (EVM) is a deterministic state machine that executes the bytecode of the smart contract identically on all nodes \cite{wood2014yellow}. However, it is not Turing complete in the classical sense: execution is strictly resource-bounded by gas - every instruction has a metered gas cost, and execution halts once the supplied gas is exhausted. 
This gas-bounded execution guarantees termination and prevents non-halting or deliberately expensive programs from stalling the network; accordingly, the EVM is often described as \emph{quasi–Turing complete} (computationally universal only under a finite gas budget) \cite{antonopoulos2018mastering}\cite{wood2014yellow}.

\subsection{Gas}
Gas is the unit of account for computational effort in Ethereum. Each EVM opcode has an associated gas cost, and a transaction specifies an upper bound (gas limit) on how much gas may be consumed during its execution.

Gas serves three core purposes: 
\begin{itemize}
    \item \emph{metering} computation and storage, so that the use of the resources is paid for by the initiator of a transaction.
    \item \emph{DoS resistance} and spam prevention, because excessively resource-intensive executions become economically infeasible \cite{wood2014yellow}\cite{article_1559}.
    \item \emph{economic prioritization} of limited block space via fees
\end{itemize}

Since EIP-1559\footnote{\url{https://eips.ethereum.org/EIPS/eip-1559}}, each block includes a dynamically adjusted \emph{base fee} that is burned and a user-specified \emph{priority fee} (tip) paid to the block proposer. 
Users submit \texttt{maxFeePerGas} and \texttt{maxPriorityFeePerGas}; the effective price paid per gas equals \(\min(\texttt{maxFeePerGas}, \text{base fee} + \texttt{maxPriorityFeePerGas})\). 
Blocks have an elastic gas target and the base fee increases or decreases depending on recent block gas usage, stabilizing the fee market while preserving incentives.


\subsection{Architecture}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{images/evm}
    \caption[Ethereum Virtual Machine illustration]{Ethereum Virtual Machine illustration\footnote{\url{https://ethereum.org/developers/docs/evm/}}.}
    \label{fig:evm}
\end{figure}

where 
\begin{itemize}
    \item Program Counter (PC) - component that tracks the current instruction that it is executing;
    \item EVM code - immutable compoennt holds the bytecode of the smart contract that is being executed.
    \item Account Storage - part of the persistent state of the blockchain where the data of smart contracts are stored permanently. There are two types of accounts in the Ethereum environment:\texttt{ (i) }Externally Owned Account (EOA) that is owned by any external entity. Most commonly, it is referred to as a user account; and\texttt{ (ii) }Smart Contract Account that is owned by a smart contract and often controlled by an EOA that interacts with the deployed smart contract \cite{Buterin2013}.
\end{itemize}

\subsection{Memory}

\begin{itemize}
    \item \textbf{Stack} - low-level memory structure that operates on a last-in, first-out (LIFO) principle. It stores small local variables and value types that are required for immediate execution. The stack is limited to 1024 elements, each 256 bits wide, and is accessible only through EVM opcodes or inline assembly. Careful management is essential, as exceeding its capacity causes the execution of the contract to fail \cite{evm_storage}.
    \item \textbf{Memory} - dynamic and expandable storage area allocated for each function execution, which is then discarded once the function has finished. Unlike the stack, which is restricted to temporary data storage, memory allows for more flexible and longer-lived data retention.
    \item \textbf{Storage} - persistent storage is associated with every smart contract and holds its state. Read and write operations in storage are relatively more expensive than those performed in memory. The data in storage are maintained as key-value pairs \cite{evm_storage_arxiv}.
    \item \textbf{Calldata} - read-only and immutable storage that holds function arguments and transaction data for the duration of a transaction call.
\end{itemize}

\section{Smart Contracts}
Building on the blockchain foundation introduced in Section~\ref{se:overview}, Ethereum extends the ledger model with \emph{smart contracts}: programs stored on-chain and executed by all nodes under the same consensus rules \cite{wood2014yellow}. In practice, this means contract execution is deterministic and publicly verifiable: anyone can inspect the code, replay transactions, and validate resulting state changes.

A contract is deployed through a transaction, receives its own on-chain address, and can then be called by externally owned accounts or by other contracts. This execution model reduces reliance on intermediaries and enables composable decentralized applications, where protocols interact as reusable building blocks.

\subsection{Solidity}
Solidity is Ethereum’s dominant high-level, statically typed, contract-oriented language, compiled into EVM bytecode \cite{soliditydocs}. Several language concepts are especially important from a security perspective:

\begin{itemize}
    \item \textbf{Visibility and interfaces} (\texttt{public}, \texttt{external}, \texttt{internal}, \texttt{private}) define which functions are callable and from where.
    \item \textbf{Data locations} (\texttt{storage}, \texttt{memory}, \texttt{calldata}) influence both correctness and gas usage.
    \item \textbf{External call primitives} (\texttt{call}, \texttt{delegatecall}, \texttt{staticcall}) shape trust boundaries and control flow.
    \item \textbf{Failure semantics} (\texttt{require}, \texttt{revert}, \texttt{assert}) determine how safely the contract handles unexpected states.
\end{itemize}

A common drawback of Solidity development is that subtle semantic errors can produce severe vulnerabilities. For example, performing an external call before updating the internal state or careless use of \texttt{delegatecall} may execute foreign code in the caller’s storage context.

\paragraph{Conceptual example}
\begin{minted}[fontsize=\small,breaklines]{solidity}
contract Counter {
    uint256 public value;

    function inc() external {
        value += 1; // persistent on-chain state update
    }
}
\end{minted}

Even this trivial piece of code captures the core model, where a transaction triggers EVM execution, the state is updated, and the transition becomes part of the verifiable blockchain history.

\section{Security}
In Ethereum, security follows directly from the execution model rather than from a separate component: transparent code, immutable state transitions, and adversarially accessible interfaces mean every design decision can become an attack surface. The next section therefore focuses on how vulnerabilities emerge in real Solidity/EVM workflows and how they can be systematically prevented.

\subsection{Vulnerability Taxonomies}
Smart contract security research and industry practice have converged on a set of recurring vulnerability categories. Two widely used resources are the Smart Contract Weakness Classification (SWC) registry and the OWASP Smart Contract Top 10, both of which provide structured names, short descriptions, and representative examples for common classes of issues \cite{swc_registry,owasp_sc_top10}. Using a shared taxonomy is not merely a reporting convenience: it enables consistent labeling across audit reports, static analyzers, and vulnerability datasets, and it makes retrieval-based systems (such as the knowledge base used later in this thesis) easier to query and evaluate.

That said, taxonomies are imperfect abstractions. Many real incidents do not map cleanly to a single label: an exploit may combine oracle manipulation with reentrancy, or rely on an access control mistake that only becomes exploitable due to an accounting bug. For this reason, we treat taxonomies as an organizational tool rather than a complete explanation of risk, and we emphasize concrete vulnerability \emph{patterns} that are actionable during analysis \cite{atzei2017survey,perez2021smart}.

\subsection{Common Vulnerability Types}
% Your “working set” of patterns referenced later by the KB.
\subsubsection*{Reentrancy and External Call Hazards}
\emph{Reentrancy} occurs when a contract makes an external call before it has fully updated its own state, allowing the callee to re-enter and observe or manipulate intermediate state \cite{luu2016making,atzei2017survey}. In practice, the underlying hazard is broader than classic reentrancy: any external call can revert unexpectedly, consume unbounded gas, or execute arbitrary code in the callee, so call ordering and error handling are security-critical \cite{consensys_best_practices}. A common mitigation is the checks-effects-interactions pattern, complemented by explicit reentrancy guards where appropriate \cite{consensys_best_practices}.
\subsubsection*{Access Control and Authorization Bugs}
\emph{Access control} issues arise when privileged operations are callable by unintended parties, or when authorization checks are missing, inconsistent, or based on manipulable state \cite{atzei2017survey,consensys_best_practices}. Typical examples include unprotected administrative functions, incorrect role checks, and unsafe assumptions about \texttt{msg.sender} in proxy and meta-transaction settings. Because Solidity and the EVM do not provide built-in role management, secure authorization is largely a matter of correct application logic and disciplined use of vetted libraries \cite{consensys_best_practices}.
\subsubsection*{DoS and Gas Griefing}
\emph{Denial of service} in Ethereum often takes the form of making a critical operation prohibitively expensive or consistently reverting. Examples include iterating over unbounded lists, relying on external calls that can be forced to revert, or designs where a single malicious participant can block progress by refusing to cooperate \cite{atzei2017survey}. Because gas imposes a hard resource budget, some failures are not ``bugs'' in the conventional sense but brittleness in protocol design under adversarial conditions. Defensive patterns include bounded iteration, pull-based payments, and explicit fail-open/fail-closed decisions with documented assumptions \cite{consensys_best_practices}.
\subsubsection*{Front-running / MEV-related Issues (when relevant)}
Ethereum transactions are visible in the mempool before inclusion, and block producers can influence ordering within a block. This creates opportunities for \emph{front-running} and broader Maximal Extractable Value (MEV) strategies, where adversaries profit from reordering or inserting transactions around a victim transaction \cite{daian2020flash}. In protocol design, this shows up as price manipulation during trades, sandwich attacks, and liquidation races. Mitigations depend heavily on the application and often require mechanism design choices (e.g., commit-reveal, batch auctions, or oracle design) rather than purely local code changes \cite{daian2020flash}.

% For each: 2–5 sentences + 1 tiny example later in Implementation/Eval if needed.

% \section{Audit Methodology}

% Smart contract auditing has evolved into a specialized discipline that combines elements of traditional software security review with domain-specific knowledge about blockchain systems and economic attack vectors. Unlike conventional software where bugs might cause crashes or data corruption, smart contract vulnerabilities can lead directly to financial losses, often measured in millions of dollars TODO(\cite{some_link/footnote}).

% Auditors begin by establishing what the system is supposed to do and identifying potential threat vectors, then systematically examine the implementation through a combination of manual review and automated tools. While human expertise remains central to catching subtle logic bugs and business logic flaws, automation has become increasingly important for handling the scale and complexity of modern DeFi protocols \cite{perez2021smart}. 

% \subsubsection*{System overview}

% \subsubsection*{Trust model}

% Before examining a single line of code, effective audits begin with understanding what the system is designed to do and what could go wrong. This specification and threat modeling phase establishes the foundation for all subsequent analysis. Auditors work with the development team to document the intended behavior of the protocol, including state invariants that should always hold, access control assumptions about who can perform which actions, and economic mechanisms that should remain balanced under all circumstances \cite{groce2018echidna}.

% State invariants are particularly critical in DeFi protocols. For example, an automated market maker (AMM) might have an invariant that the product of token reserves remains constant except during fee accrual, or a lending protocol might require that total collateral always exceeds total debt by some minimum margin. Documenting these invariants explicitly serves multiple purposes: it guides manual review by clarifying what properties to verify, it provides targets for property-based fuzzing tools, and it establishes success criteria for testing. When invariants are violated, it often indicates either a vulnerability in the code or a gap in the original specification that needs addressing.

% Trust assumptions define the threat model—which actors are assumed to be honest, which might be malicious, and what capabilities each has. A typical DeFi protocol might trust its governance multi-sig to upgrade contracts responsibly while assuming that all regular users will act to maximize their own economic benefit, including front-running transactions and exploiting any profitable vulnerabilities. External dependencies also factor into the trust model: does the protocol rely on specific oracle providers, and what happens if those oracles are compromised or manipulated? These assumptions directly influence what the auditor looks for in the code.

% This phase also identifies high-value targets—the functions and state variables most critical to protocol security and most likely to be attacked. In a lending protocol, this might be functions that calculate collateralization ratios or trigger liquidations. In a bridge, it could be the validation logic for cross-chain messages. By explicitly mapping out these critical components and their security requirements up front, auditors can allocate their limited time more effectively and ensure comprehensive coverage of the attack surface. This specification work also sets up what an LLM-based agent should retrieve when analyzing code: knowing the declared invariants and trust assumptions allows the agent to focus its limited context window on retrieving code segments most relevant to verifying those properties.

% \subsubsection{Manual Code Review}

% Manual code review remains the cornerstone of smart contract auditing despite advances in automation. Experienced auditors develop intuition about common vulnerability patterns, but more importantly, they can reason about complex interactions, business logic edge cases, and economic attack vectors that current tools struggle to identify. The review process typically proceeds through several phases, each with a different focus and level of detail.

% The review begins with architectural analysis—understanding how contracts interact, what external systems they depend on, and how data flows through the protocol. Auditors construct mental models (and often diagrams) of the system's components and their relationships. For example, in a yield aggregation protocol, they map out how user deposits flow into various strategies, how yield is calculated and distributed, and what happens during rebalancing or emergency withdrawals. This high-level understanding helps identify architectural vulnerabilities like dangerous centralization points, circular dependencies that could create reentrancy opportunities, or reliance on external systems that could fail.

% With the architecture clear, auditors move to examining critical execution paths. They trace through key user interactions step by step: what happens when Alice deposits tokens, when Bob triggers a liquidation, when governance proposes a parameter change? This path analysis helps identify missing checks, incorrect sequencing, or edge cases where the code behaves unexpectedly. Auditors pay special attention to paths involving external calls, token transfers, and state changes—the operations most likely to introduce vulnerabilities.

% Invariant verification forms another crucial part of manual review. Armed with the invariants documented during threat modeling, auditors examine whether the code actually maintains these properties under all possible executions. This often involves reasoning about potential sequences of function calls and state transitions. For instance, if a protocol claims that "users can always withdraw their proportional share of pooled assets," the auditor checks whether there are any code paths where this could fail—perhaps during contract upgrades, when certain functions are paused, or in response to specific market conditions.

% Edge case analysis requires creativity and experience. Auditors consider boundary conditions: what happens with zero values, maximum values, or just-below-overflow values? They think about timing issues: what if a transaction is front-run, what if the block timestamp is manipulated slightly, what if multiple operations happen in the same block? They examine error handling: are all failure modes properly addressed, or are there paths where errors could leave the system in an inconsistent state? This type of reasoning is difficult to automate because it requires understanding both the code's literal behavior and the protocol's semantic intent.

% The manual review process is inherently limited by human cognitive constraints. An auditor can only hold so much context in working memory at once, and complex protocols might span dozens of contracts with thousands of lines of code. This is where tool-assisted workflows become valuable—not to replace human judgment, but to help auditors manage complexity by automating context retrieval, flagging potential issues for human investigation, and maintaining consistency in coverage across a large codebase. The goal of integrating LLMs into this workflow is to augment human auditors with better information retrieval and pattern recognition, allowing them to focus their expertise on the creative reasoning tasks that machines still cannot perform.

% \subsubsection*{Static analysis}

% \subsubsection*{Local deployment}

% \subsubsection*{Tool-Based Analysis}

% Automated analysis tools have become an essential part of the smart contract audit workflow, complementing manual review by efficiently checking for known vulnerability patterns and coding errors. These tools vary in their approaches—from lightweight pattern matching to sophisticated symbolic execution—and each brings different strengths and limitations to the audit process.

% Static analysis tools examine code without executing it, using techniques ranging from simple syntactic pattern matching to complex abstract interpretation. Slither, developed by Trail of Bits, has emerged as one of the most widely adopted static analyzers for Solidity \cite{feist2019slither}. It operates on Solidity's intermediate representation (IR) and includes over 70 built-in detectors for common issues like reentrancy vulnerabilities, unprotected ether withdrawals, incorrect ERC-20 implementations, and dangerous delegatecalls. Slither's strength lies in its speed and comprehensive coverage—it can analyze a medium-sized project in seconds and rarely produces false negatives for the patterns it targets.

% However, static analyzers face fundamental limitations. They must over-approximate program behavior to be sound, which often leads to false positives—flagging code as potentially vulnerable when it's actually safe. For example, Slither might flag a reentrancy warning for any external call followed by a state change, even when the specific call cannot actually re-enter the contract. Auditors must manually review these warnings to separate real issues from noise. More critically, pattern-based detectors can only find vulnerabilities they were explicitly programmed to recognize. Novel vulnerability classes or complex logic bugs that don't match known patterns slip through entirely.

% Other static analysis tools take different approaches. Mythril employs symbolic execution and SMT solving to explore possible execution paths and find states that violate security properties \cite{mueller2018mythril}. This can uncover deeper issues than pattern matching, but symbolic execution doesn't scale well to large contracts or complex path conditions—the number of possible paths grows exponentially with program size and branching. Securify uses a dataflow analysis framework and security patterns specified in a domain-specific language \cite{tsankov2018securify}, offering more flexibility in specifying what to look for but requiring expertise to write effective patterns.

% Linters like Solhint and Ethlint catch style violations and potential code quality issues rather than security vulnerabilities per se. While less critical than security-focused analyzers, they help maintain code quality that makes contracts easier to audit. They flag issues like missing visibility specifiers, unused variables, overly complex functions, and deviations from best practice patterns like checks-effects-interactions.

% Integration of multiple tools provides better coverage than relying on any single analyzer. A typical audit workflow might run Slither for quick pattern detection, Mythril for deeper analysis of critical functions, and various linters for code quality checks. However, this multi-tool approach creates new challenges: each tool has its own output format, overlapping detections need deduplication, and the auditor must triage dozens or hundreds of findings to identify which require attention.

% This is where the Wake framework becomes relevant to our work. Wake provides a Python-based infrastructure for building custom detectors and integrating various analysis tools in a unified workflow \cite{wake2023documentation}. Unlike standalone tools that operate in isolation, Wake allows auditors to write detectors that combine insights from multiple sources—for example, using both AST pattern matching and data flow analysis to reduce false positives. Wake's Python ecosystem also makes it a natural bridge to LLM-based analysis: we can extract rich context from Wake's analysis passes and feed it to language models that can reason about patterns too complex for rule-based systems.

% The key insight for our work is that automated tools excel at scalable, repeatable pattern matching but struggle with novel vulnerabilities and contextual reasoning. Meanwhile, LLMs demonstrate strong pattern recognition on code they've seen during training and can generate natural language explanations, but they lack the precision and soundness guarantees of formal methods. By combining static analysis tools with LLM reasoning in an agent-based architecture—using tools like Wake to extract structured information and RAG to provide relevant context—we aim to get closer to the best of both approaches.

% \subsubsection*{Local deployment}

% Testing smart contracts in realistic conditions requires deploying them to a local blockchain environment where their behavior can be observed without risking real funds or incurring transaction costs. Modern development frameworks like Hardhat, Foundry, and Wake provide robust local testing infrastructure that has become standard in the audit workflow \cite{hardhat2023, foundry2023}.

% Unit tests verify individual functions in isolation, checking that they produce expected outputs for given inputs and properly handle error conditions. Integration tests examine how multiple contracts interact, ensuring that complex workflows execute correctly end-to-end. For example, testing a lending protocol might involve simulating a sequence of deposits, borrows, interest accrual, and liquidations to verify that all state transitions occur correctly and invariants are maintained. Well-written test suites serve both as verification of correct behavior and as documentation of intended functionality.

% Fork testing represents a particularly powerful technique for smart contract auditing. Rather than testing in isolation, fork testing deploys the contract under audit to a local blockchain that has copied the state of mainnet at a specific block. This allows the contract to interact with real deployed protocols—actual DEXes, oracles, tokens—without requiring the auditor to mock these complex systems. For example, when auditing a yield optimization strategy, fork testing can verify that the strategy actually generates yield when deployed against real DeFi protocols, that it handles real market conditions correctly, and that it responds appropriately to real oracle updates.

% Fork testing also enables reproduction and investigation of historical exploits. By forking at a block just before a known attack, auditors can replay the attack transaction to understand exactly how it worked, then test whether proposed fixes would have prevented it. This forensic capability helps validate that audit recommendations actually address the vulnerabilities they target. Wake's testing framework includes sophisticated fork testing capabilities, allowing tests to manipulate fork state, impersonate arbitrary accounts, and observe detailed execution traces.

% Despite their value, tests have inherent limitations. Test coverage is only as good as the test cases written—they can demonstrate the presence of bugs but never prove their absence. Auditors who rely too heavily on "the tests pass" as evidence of security may miss edge cases that weren't considered when writing tests. Additionally, tests typically focus on expected usage patterns, while attackers deliberately seek unexpected input combinations and state transitions that developers didn't anticipate.

% This limitation motivates property-based testing approaches, where instead of writing individual test cases, auditors specify properties that should always hold and let the testing framework automatically generate inputs trying to violate those properties. This bridges to our next topic: fuzz testing, which takes this idea even further by using randomization and evolutionary algorithms to explore the state space more thoroughly than human-written tests ever could.

% \subsubsection*{Fuzz testing}

% Fuzzing has emerged as one of the most effective techniques for uncovering subtle bugs in smart contracts, particularly logic errors that evade static analysis and aren't covered by manual test cases. Unlike traditional testing where humans specify input values, fuzzing automatically generates large numbers of random or semi-random inputs to explore program behavior across a wide range of scenarios \cite{trail2023fuzz}.

% The simplest form of fuzzing, random input generation, feeds functions with arbitrary values and checks whether they crash, revert unexpectedly, or violate assertions. While naive, this approach can quickly find boundary condition bugs—what happens with zero values, maximum uint256 values, or unexpected combinations? More sophisticated fuzzers use coverage-guided generation, tracking which code paths have been executed and favoring inputs that reach new branches. This evolutionary approach efficiently explores the state space, focusing computational effort on finding inputs that trigger novel behaviors.

% Property-based fuzzing, exemplified by tools like Echidna \cite{grieco2020echidna} and Foundry's fuzzer \cite{foundry2023}, takes this further by allowing auditors to specify invariants that should always hold. The fuzzer then attempts to find any sequence of function calls and inputs that violates these invariants. For example, an auditor might specify that "total shares times share price should equal total assets" for a vault contract. The fuzzer will generate thousands of random deposit, withdraw, and transfer operations, checking after each whether this invariant still holds. When it finds a violation, it automatically minimizes the test case to the simplest sequence that reproduces the issue.

% Stateful fuzzing considers sequences of operations rather than isolated function calls. Many vulnerabilities only emerge through specific state transitions—for example, a reentrancy bug that requires calling function A to set up state, then reentering during a call to function B to exploit that state. Echidna maintains a model of contract state and generates sequences of transactions that explore different state transition paths. This catches bugs that unit tests miss because the test writer didn't consider that particular sequence of operations.

% Fuzzing excels at finding logic bugs—violations of business rules or implicit assumptions that static analyzers can't detect because they aren't simple pattern matches. For instance, fuzzing might discover that a specific sequence of deposits and withdrawals allows a user to extract more funds than they deposited, or that under certain market conditions a pricing oracle can be manipulated. These are precisely the high-impact bugs that make auditing challenging: they're correct in terms of type safety and basic invariants, but incorrect in terms of the protocol's economic logic.

% However, fuzzing has limitations. It's probabilistic rather than exhaustive—finding a bug depends on the fuzzer happening to generate the right sequence of inputs, which might be a tiny fraction of the total input space. Complex bugs requiring specific state setups might be missed if the fuzzer doesn't happen to explore that path. Additionally, writing good invariant specifications requires expertise—if the auditor doesn't correctly specify what should always be true, the fuzzer won't detect violations.

% The integration of fuzzing into the audit workflow has become standard practice. Auditors typically run fuzzers overnight or over weekends, generating millions of test cases to explore state spaces too large for manual testing. When combined with static analysis (which finds known patterns quickly) and manual review (which applies human reasoning about business logic), fuzzing provides a powerful third pillar in the defense against vulnerabilities. For our work with LLM-based agents, fuzzing results provide valuable signal: when a fuzzer finds an invariant violation, the LLM can analyze the failing sequence to explain why it violates the invariant and suggest fixes.

% Rather than viewing automation as competing with human auditors, we see it as extending their capabilities. The techniques we've discussed generate vast amounts of information: static analyzers flag hundreds of potential issues, tests exercise thousands of state transitions, fuzzers generate millions of inputs. Making effective use of this information requires systems that can retrieve relevant context, synthesize insights across tools, and present findings in ways that augment human reasoning.

% The code analysis approaches we examine next build on the audit methodology foundations established here. We explore how static analysis frameworks like Wake provide structured access to code properties, how retrieval systems can surface relevant code segments for LLM analysis, and how agent architectures can orchestrate multiple tools to tackle complex analysis tasks. The goal is not to replace the auditor workflows described in this chapter, but to make them more efficient and effective by automating the retrieval and synthesis steps that currently consume significant auditor time.

\chapter{Code Analysis}
\label{ch:code-analysis}

% Goal: describe analysis methods you'll reference when positioning Wake/Wake-AI and your RAG design.

The security analysis of software systems, particularly smart contracts deployed on blockchain platforms, relies on a diverse set of analytical techniques that have evolved over decades of programming language research. This chapter provides a comprehensive overview of the foundational methods for code analysis, establishing the theoretical and practical groundwork necessary for understanding how modern tools—including Wake and its AI-augmented extensions—approach vulnerability detection in Solidity smart contracts. We organise our discussion around three complementary paradigms: static analysis, which reasons about program behaviour without execution; dynamic analysis, which observes actual runtime behaviour; and formal verification, which provides mathematical guarantees about program correctness.

\section{Static Analysis}
\label{sec:static-analysis}

Static analysis encompasses techniques that examine source code, bytecode, or other program representations to infer properties about all possible executions without actually running the program~\cite{nielson1999principles}. The appeal of static analysis lies in its soundness guarantees—a sound static analyser will never miss a bug of the class it is designed to detect—and its ability to reason about infinite execution paths. However, this power comes at the cost of precision: static analysers may report false positives, flagging code as potentially buggy when no actual vulnerability exists~\cite{rice1953classes}.


\subsection{Abstract Syntax Tree}
\label{subsec:ast}

The abstract syntax tree (AST) serves as the foundational representation for most static analysis techniques. An AST is a hierarchical tree structure that captures the syntactic structure of source code while abstracting away concrete details such as whitespace, comments, and parentheses that do not affect program semantics~\cite{aho2006compilers}. Each node in the tree corresponds to a syntactic construct—a function declaration, an assignment statement, a binary expression—and the tree's structure reflects the nesting and composition of these constructs.

[TODO describe AST maps to code]

However, the AST has significant limitations for semantic analysis. Because it captures only syntactic structure, it cannot directly represent the flow of data through a program or the possible paths of control flow. Two syntactically similar code fragments may exhibit vastly different runtime behaviours depending on the values of variables and the paths taken through conditional statements. These limitations motivate the use of more semantically rich representations.

\subsection{Intermediate Representation}
\label{subsec:ir}

Intermediate representations (IRs) bridge the gap between source-level syntax and low-level execution semantics by normalizing diverse syntactic constructs into a uniform format amenable to analysis~\cite{muchnick1997advanced}. A well-designed IR strips away syntactic sugar, resolves implicit operations, and exposes the underlying computational structure of the program. {FIX OLD CITE}

[TODO smth interesting in general related to code]

\subsection{Control Flow Analysis}
\label{subsec:control-flow}

Control flow analysis (CFA) determines the possible paths of execution through a program, representing this information as a control flow graph (CFG) where nodes represent basic blocks—sequences of instructions with no internal branching—and edges represent possible transfers of control~\cite{allen1970control}. The CFG provides the structural backbone for many subsequent analyses, enabling reasoning about path reachability, loop structure, and the ordering of operations.

[Again old cite, if you cite ,you can directly copy text from book or web page]


The call graph, a related structure that captures the calling relationships between functions, extends control flow analysis to the interprocedural level. Each node in the call graph represents a function, and edges represent potential call relationships. In the presence of dynamic dispatch—common in object-oriented languages and in Solidity's inheritance system—call graph construction becomes challenging, as the target of a call may depend on runtime type information~\cite{grove2001framework}.
entially leading to precision loss.

[TODO some grapth with explanation, image]

Reachability analysis over the CFG determines which program points can potentially be reached from a given starting point. This analysis is fundamental for pruning infeasible paths from consideration and for establishing preconditions under which vulnerabilities can be triggered. If a vulnerable code pattern exists only on unreachable paths, it poses no actual security risk.

\subsection{Data Flow Analysis}
\label{subsec:data-flow}

Data flow analysis tracks how values flow through a program, determining at each program point which values may be produced and consumed~\cite{kildall1973unified}. The classic formulation employs the monotone framework, which computes fixed points over the lattice of possible data flow facts by iteratively propagating information along CFG edges until no further changes occur~\cite{kam1977monotone}.

The reaching definitions analysis, a foundational data flow analysis, determines for each use of a variable which definitions (assignments) might reach that use. This information enables detection of uninitialised variables, dead code, and various forms of data dependency. For smart contract security, reaching definitions help establish whether user-controlled input can influence security-critical operations~\cite{yamaguchi2014modeling}.

Taint analysis, a specialisation of data flow analysis, tracks the flow of untrusted data from sources (such as transaction parameters) to security-sensitive sinks (such as external calls or state modifications)~\cite{schwartz2010all}. In the smart contract domain, taint sources include \texttt{msg.sender}, \texttt{msg.value}, \texttt{calldata}, and return values from external calls. Sinks include operations that transfer value, modify access control state, or perform external calls. A taint flow from source to sink without proper sanitisation indicates a potential vulnerability.

Data flow analysis faces particular challenges in Solidity due to storage aliasing. Solidity's storage model maps state variables to 256-bit storage slots according to complex packing rules, and dynamic data structures such as mappings and arrays use hash-based slot computation~\cite{antonopoulos2018mastering}. Two syntactically distinct storage references may alias to the same slot, creating data flow paths invisible to na\"ive analysis. Precise handling of storage aliasing requires modelling Solidity's storage layout rules and potentially employing alias analysis techniques~\cite{andersen1994program}.

\section{Dynamic Analysis}
\label{sec:dynamic-analysis}

While static analysis reasons about all possible executions, dynamic analysis observes actual program behaviour during concrete executions. This complementary approach sacrifices soundness—a dynamic analysis can only observe the executions it actually runs—in exchange for precision: the behaviours observed during dynamic analysis represent actual, not merely potential, program behaviour. [TODO cite]

\subsection{Fuzz Testing}
\label{subsec:fuzz-testing}

Fuzz testing (fuzzing) is a dynamic testing technique that automatically generates test inputs to explore program behaviour and discover bugs [TODO cite smth normal related to text and fuzzing, not book from 1980 year]. Modern fuzzing has evolved significantly from its origins in random input generation, incorporating coverage guidance, constraint solving, and domain-specific knowledge to systematically explore program state space~\cite{manes2019art}.

[TODO maybe a table with some stats interesting, then refernece and small discussion about it]

Invariant-based fuzzing provides properties that should hold across all reachable states. The fuzzer then attempts to generate transaction sequences that violate these invariants. Common invariants include balance conservation (total value in should equal total value out), access control consistency (only authorised addresses can perform privileged operations), and state machine integrity (the contract should only be in valid states)~\cite{wustholz2020harvey}.

Coverage-guided fuzzing uses feedback from previous executions to guide input generation toward unexplored program regions. By instrumenting the contract to track which code paths are exercised, the fuzzer can prioritise inputs that reach new coverage, systematically expanding the explored state space~\cite{nguyen2020sfuzz}. The combination of coverage guidance with property-based testing provides a powerful technique for discovering subtle vulnerabilities that escape both manual review and pattern-based static analysis.

Corpus generation and management play crucial roles in fuzzing effectiveness. The corpus—the set of seed inputs from which the fuzzer generates new inputs—significantly influences exploration efficiency. Techniques such as corpus distillation, which removes redundant inputs that do not contribute new coverage, and corpus scheduling, which prioritises inputs likely to lead to new discoveries, improve fuzzing throughput~\cite{rebert2014optimizing}.

\section{Formal Verification}
\label{sec:formal-verification}

Formal verification employs mathematical techniques to prove that programs satisfy specified properties with certainty, not merely with high probability as testing provides~\cite{clarke2018model}. While static analysis and testing may miss vulnerabilities or report false positives, formal verification can provide guarantees: if verification succeeds, the property provably holds; if it fails, a concrete counterexample demonstrates the violation.

However, formal verification faces significant practical challenges. The techniques are computationally expensive, often requiring substantial manual effort to specify properties and guide the verification process. Scalability limitations restrict application to smaller codebases or require abstraction that may introduce imprecision. Additionally, verification establishes conformance to specification, but specifications themselves may be incomplete or incorrect, leaving gaps in security coverage.

[TODO mention, that even itis well known existed technique for dynami analysis, it has very weak application in Ehereum and smart contracts]

\subsection{Symbolic Execution}
\label{subsec:symbolic-execution}

Symbolic execution executes programs with symbolic rather than concrete values, representing program state as logical constraints over symbolic variables~\cite{king1976symbolic}. Rather than computing specific outputs for specific inputs, symbolic execution computes expressions over symbolic inputs that characterise the relationship between inputs and outputs. At branch points, execution forks to explore both paths, accumulating path conditions that constrain the symbolic inputs consistent with each path.

For vulnerability detection, symbolic execution enables systematic exploration of program paths and automatic generation of inputs that trigger specific behaviours. Given a property to check—such as the absence of integer overflow—symbolic execution explores paths, collects constraints under which the property is violated, and queries a satisfiability modulo theories (SMT) solver to determine whether satisfying inputs exist. If the solver finds a satisfying assignment, it provides a concrete exploit input; if the constraints are unsatisfiable, the property holds on that path~\cite{cadar2008exe}.

Symbolic execution faces the path explosion problem: the number of paths through a program grows exponentially with the number of branch points. Loops and recursive calls exacerbate this problem, potentially creating infinite paths. Practical symbolic execution engines employ various strategies to manage path explosion, including bounded exploration, state merging, and prioritised search~\cite{cadar2013symbolic}.

In the smart contract domain, tools such as Mythril~\cite{mueller2018smashing} and Manticore~\cite{mossberg2019manticore} employ symbolic execution to detect vulnerabilities. These tools symbolically execute EVM bytecode, modelling the Ethereum execution environment including storage, message calls, and environmental variables. When a path reaches a potentially vulnerable state—an external call with user-controlled destination, an arithmetic operation that may overflow—the tool checks whether the path is feasible and, if so, reports the vulnerability with a triggering input.

Environment modelling presents particular challenges for smart contract symbolic execution. The blockchain environment includes not just the contract under analysis but the entire ecosystem of other contracts, the block context, and the transaction parameters. Accurate modelling requires assumptions about what external contracts might do, what values environmental variables might take, and how transactions might be sequenced. Conservative assumptions lead to false positives; optimistic assumptions may miss real vulnerabilities~\cite{luu2016making}.

% [https://www.cyfrin.io/blog/solidity-smart-contract-formal-verification-symbolic-execution#layer-4-or-formal-verification]

\subsection{Theorem Proving}
\label{subsec:theorem-proving}

Theorem proving represents the most powerful—and most demanding—approach to formal verification. Rather than exhaustively exploring state space, theorem proving directly constructs mathematical proofs that programs satisfy specifications. Interactive theorem provers such as Coq~\cite{bertot2013interactive}, Isabelle~\cite{nipkow2002isabelle}, and Lean~\cite{moura2021lean} provide frameworks for developing machine-checked proofs with human guidance.

The expressiveness of theorem proving is unmatched: any mathematically statable property can, in principle, be proven. This includes properties beyond the reach of model checking and symbolic execution, such as correctness relative to complex mathematical specifications or security properties involving cryptographic assumptions. Projects such as the Ethereum Foundation's formal specification efforts demonstrate the application of theorem proving to blockchain protocol verification~\cite{hirai2017defining}.

However, the cost of theorem proving is substantial. Proofs require significant human expertise to construct, often taking person-months of effort for non-trivial systems. The proof development process requires not just programming skill but mathematical sophistication and familiarity with the proof assistant's logic and tactics. For most smart contract development contexts, this cost-benefit trade-off renders full theorem proving impractical.

Nonetheless, theorem proving plays an important role in the broader smart contract security ecosystem. Proofs of foundational libraries, such as safe arithmetic operations or standard token implementations, can be developed once and reused widely. High-value contracts managing billions of dollars may justify the investment in formal proofs. The verification of compiler correctness ensures that properties proven at the source level are preserved through compilation~\cite{leroy2009formal}.


\section{Summary and Transition to LLM-based Analysis}
\label{sec:summary-transition}

This chapter has surveyed the foundational techniques for program analysis as applied to smart contract security. Static analysis, operating on representations from abstract syntax trees to interprocedural data flow, provides scalable vulnerability detection with soundness guarantees but may produce false positives. Dynamic analysis, through transaction tracing and fuzz testing, observes actual behaviours with precision but cannot guarantee absence of vulnerabilities. Formal verification offers mathematical certainty but at significant computational and human cost.

Each technique occupies a distinct point in the trade-off space between soundness, completeness, scalability, and automation. In practice, effective security analysis combines multiple techniques: static analysis for broad coverage and early detection, dynamic analysis for validation and edge case discovery, and selective formal verification for highest-assurance components. This defence-in-depth approach acknowledges that no single technique suffices for comprehensive security assessment.

Despite the sophistication of these techniques, significant challenges remain. The semantic gap between source code and natural language makes it difficult for automated tools to understand programmer intent, leading to both false positives (flagging intended behaviour as bugs) and false negatives (missing bugs that violate unstated invariants). The evolving landscape of smart contract patterns, from novel DeFi primitives to cross-chain bridges, continuously introduces new vulnerability classes that existing detectors may not recognise~\cite{werner2022sok}.

Recent advances in large language models (LLMs) offer a promising complementary approach. LLMs trained on vast corpora of code and natural language have demonstrated remarkable capabilities in code understanding, generation, and analysis~\cite{chen2021evaluating}. Their ability to process natural language specifications, understand contextual patterns, and generalise from examples positions them as potential contributors to security analysis workflows.

However, LLMs also exhibit significant limitations for security-critical applications. They may hallucinate non-existent vulnerabilities, miss subtle bugs, or provide confident but incorrect assessments~\cite{pearce2022asleep}. Their probabilistic nature provides no formal guarantees, and their sensitivity to prompt formulation introduces variability in outputs. Integrating LLMs into security analysis requires careful consideration of their strengths and limitations.

The subsequent chapters explore how LLM capabilities can augment traditional analysis techniques. We examine retrieval-augmented generation (RAG) architectures that ground LLM outputs in verified knowledge bases, reducing hallucination while preserving the flexibility and natural language understanding that LLMs provide. Wake-AI, our proposed system, demonstrates this integration, combining Wake's precise static analysis with LLM-based contextual understanding and explanation generation. This hybrid approach seeks to leverage the complementary strengths of symbolic and neural methods, advancing toward more effective, accessible, and reliable smart contract security analysis.


\chapter{Large Language Models}
\label{ch:llm}

% ============================================================
%  CHAPTER OPENING — from sequence modelling math to transformers
% ============================================================

The previous chapter showed that static analysis has broad usage in identifying many vulnerability patterns in codes. But it also showed the limitation that not all types of vulnerability could be described by rule, especially logical issues. The natural question follows --- can a model recognize a vulnerable pattern [TODO]?

Answering that question requires a detour through the mathematics of sequence modeling, because the architectures that power today's Large Language Models (LLMs) grew directly out of attempts to assign probabilities to sequences of symbols.

\section{Sequence Probabilities}
\label{sec:seq-prob}

Let $\mathbf{x} = (x_1, x_2, \dots, x_T)$ be a sequence of tokens (words) in English, opcodes in EVM bytecode, or lexemes in Solidity source. A \emph{language model} assigns a probability to the whole sequence by factoring it in with the chain rule of probability:

\begin{equation}
    P(\mathbf{x}) \;=\; \prod_{t=1}^{T} P\!\bigl(x_t \mid x_1, \dots, x_{t-1}\bigr).
    \label{eq:chain-rule}
\end{equation}

Each factor on the right-hand side determines the likelihood of the the next token given everything that came before. Classical $n$-gram models approximate this by truncating the history to a fixed window of $n{-}1$ tokens, an assumption that works acceptably for short phrases but collapses when the prediction depends on context dozens or hundreds of tokens back~\cite{hindle2012naturalness}.

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: side-by-side comparison of n-gram (fixed window) vs.
% RNN (hidden state chain) vs. Transformer (full attention matrix)
% showing how each architecture "sees" context.
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\textwidth]{images/context_comparison.pdf}
%     \caption{Context access patterns in three sequence modelling paradigms.
%              An $n$-gram model sees only the previous $n{-}1$ tokens (shaded window).
%              An RNN compresses all prior tokens into a single hidden state vector (arrow chain).
%              A transformer attends to every prior token in parallel (full attention matrix).}
%     \label{fig:context-comparison}
% \end{figure}
% ─────────────────────────────────────────────────────────────

\subsection{Recurrent Neural Networks}

Recurrent Neural Networks (RNNs) offered the first neural solution to variable-length conditioning.  At each time step $t$, an RNN updates a hidden state that summarizes the entire prefix:

\begin{equation}
    \mathbf{h}_t = f\!\bigl(\mathbf{W}_h \mathbf{h}_{t-1} + \mathbf{W}_x \mathbf{x}_t + \mathbf{b}\bigr),
    \label{eq:rnn}
\end{equation}

where $f$ is a nonlinearity such as $\tanh$ or ReLU, and $\mathbf{W}_h$, $\mathbf{W}_x$ are learned weight matrices.  The conditional distribution for the next token is then read off from $\mathbf{h}_t$.

\begin{figure}[!h]
    \centering
    \includegraphics[width=11cm, height=9cm]{images/RNN.pdf}
    \caption{Recurrent Neural Network architecture.}
    \label{fig:rnn_diagram}
\end{figure}

The Figure \ref{fig:rnn_diagram} shows three main layers of RNN, and recurrent connection that feeds the hidden state from one time step to the next, allowing the network to maintain a memory of previous inputs. All recurrent connections share the same weight matrix, enabling the network to process variable-length sequences.

In principle, the hidden state can carry information from arbitrarily far back.  In practice, gradients that flow through long chains of multiplication either vanish or explode, a phenomenon analysed formally by Bengio et al.~\cite{bengio1994learning}. [TODO ADD MORE ABOUT VANIHING GRADIENT]

\subsubsection*{Long Short-Term Memory}
Long Short-Term Memory (LSTM) networks~\cite{hochreiter1997long} mitigated vanishing gradients by introducing gated memory cells, but the fundamental bottleneck remained: processing is strictly sequential.  Token $t$ cannot be computed until token $t{-}1$ has been processed.  This makes training on large code corpora prohibitively slow—and it also means that information about a variable declared in line~5 must survive passage through every intermediate hidden state before it can influence the analysis of that variable's use in line~150.


% ============================================================
\section{Transformers}
\label{sec:transformers}
% ============================================================

The transformer, introduced by Vaswani et al.\ in 2017~\cite{vaswani2023attentionneed}, replaced the sequential hidden-state chain with a mechanism that lets every token look directly at every other token --- \emph{self-attention}.  The result is a model that can be trained in parallel across all positions and that provides short, direct gradient paths between any pair of tokens regardless of their distance in the sequence.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/transformer.png}
    \caption{The original encoder–decoder transformer architecture~\cite{vaswani2023attentionneed}. Modern LLMs typically use only the decoder stack (right half) for autoregressive generation, or only the encoder stack (left half) for representation learning.}
    \label{fig:transformer}
\end{figure}

The full architecture is an encoder–decoder stack, but most models relevant to code analysis use only one half.  Encoder-only models such as BERT~\cite{devlin2019bert} and CodeBERT~\cite{feng2020codebert} produce contextual embeddings useful for classification and retrieval.  Decoder-only models in the GPT family~\cite{radford2019language, brown2020language} generate text autoregressively and form the backbone of today's chat-capable LLMs (GPT-4, Claude, LLaMA).  Encoder–decoder models such as T5~\cite{raffel2020exploring} and CodeT5~\cite{wang2021codet5} excel at sequence-to-sequence tasks like code summarisation and translation.

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: Visual taxonomy — Encoder-only (BERT, CodeBERT),
% Decoder-only (GPT, LLaMA, Claude), Encoder-Decoder (T5, CodeT5).
% Show which part of the transformer each variant uses, highlighted.
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=0.85\textwidth]{images/model_taxonomy.pdf}
%     \caption{Transformer model families.  Encoder-only models (left) produce bidirectional 
%              representations; decoder-only models (centre) generate tokens autoregressively; 
%              encoder–decoder models (right) map input sequences to output sequences.}
%     \label{fig:model-taxonomy}
% \end{figure}
% ─────────────────────────────────────────────────────────────


\subsection{Self-Attention Mechanism}
\label{subsec:self-attention}

Self-attention is the operation that gives transformers their power.  Each token is projected into three vectors—a \emph{query}~$\mathbf{q}$, a \emph{key}~$\mathbf{k}$, and a \emph{value}~$\mathbf{v}$—through learned linear maps:

\begin{equation}
    \mathbf{Q} = \mathbf{X}\mathbf{W}^Q, \qquad
    \mathbf{K} = \mathbf{X}\mathbf{W}^K, \qquad
    \mathbf{V} = \mathbf{X}\mathbf{W}^V,
    \label{eq:qkv}
\end{equation}

where $\mathbf{X} \in \mathbb{R}^{T \times d_{\text{model}}}$ is the matrix of input embeddings and $\mathbf{W}^Q, \mathbf{W}^K \in \mathbb{R}^{d_{\text{model}} \times d_k}$, $\mathbf{W}^V \in \mathbb{R}^{d_{\text{model}} \times d_v}$ are the projection matrices.  The attention output is then:

\begin{equation}
    \text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V})
    \;=\; \text{softmax}\!\left(\frac{\mathbf{Q}\mathbf{K}^{\!\top}}{\sqrt{d_k}}\right)\mathbf{V}.
    \label{eq:attention}
\end{equation}

The matrix $\mathbf{Q}\mathbf{K}^{\!\top} \in \mathbb{R}^{T \times T}$ contains the compatibility score of every query–key pair.  Dividing by $\sqrt{d_k}$ prevents the dot products from growing with the embedding dimension, which would push softmax into saturation and produce near-zero gradients~\cite{vaswani2017attention}.  After softmax normalisation, each row becomes a probability distribution over positions, and the output for each token is the corresponding weighted average of value vectors.

An intuitive reading in the context of Solidity code: the query at position~$t$ asks ``what do I need to know?'', the keys at all other positions advertise ``here is what I contain'', and the resulting attention weights decide how much each position contributes to the representation at~$t$.  For instance, when the model encounters a \texttt{call.value()} invocation, its query can attend directly to the location where the receiving address was assigned, even if hundreds of tokens intervene—something an RNN could achieve only if that information survived the entire hidden-state chain.

\subsubsection*{Multi-Head Attention}

Rather than computing a single attention function, transformers run $h$ independent attention heads in parallel, each with its own projection matrices, and concatenate the results:

\begin{equation}
    \text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V})
    = \text{Concat}\!\bigl(\text{head}_1,\;\ldots,\;\text{head}_h\bigr)\,\mathbf{W}^O,
    \label{eq:multihead}
\end{equation}
\begin{equation}
    \text{where}\quad \text{head}_i = \text{Attention}\!\bigl(\mathbf{X}\mathbf{W}^Q_i,\;\mathbf{X}\mathbf{W}^K_i,\;\mathbf{X}\mathbf{W}^V_i\bigr).
    \label{eq:head-i}
\end{equation}

Empirical probing studies show that different heads specialise in different relation types—syntactic dependencies, coreference, data flow—even without explicit supervision~\cite{clark2019does, vig2019analyzing}.  For vulnerability detection, this means the model can simultaneously track variable definitions and uses in one head, function call chains in another, and common vulnerability idioms in a third, before combining these perspectives through the output projection~$\mathbf{W}^O$.


\subsection{Positional Encoding}
\label{subsec:pos-enc}

Self-attention is \emph{permutation-equivariant}: shuffling the input tokens produces the same outputs in shuffled order.  Since token order carries critical semantic information—both in natural language and in code—positional encoding must inject position information before attention is applied.

[TODO]

[TODO maybe some transition how it is possible to manipulate with these architectures, like training and so on]


% ============================================================
\section{Training Paradigms}
\label{sec:training}
% ============================================================

Building a useful LLM involves three broad stages, each with distinct implications for code security. [TODO write a bit more, that will lead that training tuning and prompntg will be sdescribed]

\subsection{Pre-training}
\label{subsec:pretraining}

Pre-training exposes the model to massive text corpora using self-supervised objectives that require no human labelling.  For decoder-only models, the objective is \emph{next-token prediction} (causal language modelling): given a prefix $x_1, \ldots, x_{t-1}$, maximise $\log P(x_t \mid x_1, \ldots, x_{t-1})$ summed over all positions and all documents in the corpus.  For encoder-only models like BERT~\cite{devlin2019bert}, the objective is \emph{masked language modelling}: randomly mask a fraction of tokens and train the model to recover them from bidirectional context.

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: Pre-training objectives visualised.
% Left: Causal LM — each token predicts the next, arrows flow left-to-right.
% Right: Masked LM — bidirectional arrows, [MASK] tokens highlighted.
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=0.85\textwidth]{images/pretraining_objectives.pdf}
%     \caption{Two pre-training objectives.  \textbf{Left}: causal language modelling (decoder-only)—each 
%              token predicts the next.  \textbf{Right}: masked language modelling (encoder-only)—randomly 
%              masked tokens are predicted from bidirectional context.}
%     \label{fig:pretraining}
% \end{figure}
% ─────────────────────────────────────────────────────────────

For code, pre-training has a dual effect.  It teaches syntactic fluency and common programming idioms that transfer across repositories, which is valuable for code comprehension.  But it also absorbs patterns from the training corpus uncritically, including insecure practices that happen to be common in open-source code~\cite{pearce2022asleep}.  An LLM's familiarity with typical code can help it spot anomalous or suspicious constructs, but pre-training alone provides no guarantee that its security judgements are correct—a limitation that motivates every subsequent stage.


\subsection{Fine-tuning}
\label{subsec:finetuning}

Fine-tuning adapts a pre-trained model to specific downstream tasks by continuing training on a smaller, curated dataset.  The most common modern approach is \emph{supervised fine-tuning} (SFT) on instruction–response pairs, which teaches the model to follow user intent reliably.

For security auditing, fine-tuning can improve output quality in two key ways: it can bias the model toward structured reporting (severity, evidence, remediation steps) and it can improve adherence to epistemic constraints such as ``only claim what you can justify with code evidence.''  However, fine-tuning also risks overfitting to narrow datasets.  For this thesis, we treat fine-tuning as complementary rather than required: grounding through retrieval and tool integration can improve reliability even when using general-purpose models.

\textbf{Parameter-efficient methods} have made fine-tuning accessible even for large models.  LoRA (Low-Rank Adaptation)~\cite{hu2022lora} freezes the pre-trained weights and injects small trainable low-rank matrices, reducing the number of trainable parameters by orders of magnitude.  QLoRA~\cite{dettmers2023qlora} combines LoRA with 4-bit quantisation of the frozen weights.  These techniques are widely used in the smart contract domain: for instance, ParaVul~\cite{huang2025paravul} extends QLoRA with sparse connections (SLoRA) for vulnerability detection, and LLM-BSCVM~\cite{llmbscvm2025} fine-tunes CodeLlama-13B with LoRA adapters for multi-agent vulnerability management.

\subsubsection*{Reinforcement Learning from Human Feedback}

After SFT, many production LLMs undergo alignment via \emph{Reinforcement Learning from Human Feedback} (RLHF)~\cite{ouyang2022training}.  The process has three stages:

\begin{enumerate}
    \item \textbf{Reward model training.}  Human annotators rank multiple model outputs for the same prompt.  A reward model is trained on these preference pairs to predict which outputs humans would prefer.
    
    \item \textbf{Policy optimisation.}  The language model is treated as a reinforcement learning agent whose ``action'' at each step is the next token.  Using Proximal Policy Optimisation (PPO)~\cite{schulman2017proximal}, the model is fine-tuned to maximise the reward model's score while staying close to the SFT policy (via a KL-divergence penalty).
    
    \item \textbf{Iteration.}  The process repeats: new outputs are collected, annotators provide fresh rankings, and the reward model and policy are updated.
\end{enumerate}

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: RLHF pipeline diagram — three stages:
% (1) SFT model generates outputs
% (2) Human annotators rank outputs → reward model trained
% (3) PPO fine-tunes the model against the reward model
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=0.85\textwidth]{images/rlhf_pipeline.pdf}
%     \caption{The RLHF alignment pipeline.  An SFT model generates candidate responses.  
%              Human annotators rank them to train a reward model.  The language model is then 
%              fine-tuned with PPO to maximise the reward while staying close to the SFT policy.}
%     \label{fig:rlhf}
% \end{figure}
% ─────────────────────────────────────────────────────────────

An alternative gaining traction is \textbf{Direct Preference Optimisation (DPO)}~\cite{rafailov2023dpo}, which eliminates the separate reward model by directly optimising the language model on preference pairs.  Smart-LLaMA-DPO~\cite{yu2025smartllama} uses this approach for smart contract vulnerability detection, applying DPO on paired high-quality and low-quality vulnerability explanations to improve both detection accuracy and explanation quality.


\subsection{Prompting}
\label{subsec:prompting}

\emph{Prompting} shapes model behaviour at inference time through instructions, context, and examples—without changing any model weights.  Brown et al.~\cite{brown2020language} demonstrated that including a few input–output examples (\emph{few-shot prompting}) can elicit task-specific behaviour from large decoder-only models without any fine-tuning at all.

For code auditing, prompts typically combine: (i) a description of the vulnerability class to check, (ii) the relevant code snippets, and (iii) an expected output format.  Prompting is powerful but fragile—small wording changes can shift conclusions, and including too much irrelevant context degrades output quality.  These realities motivate the retrieval-augmented prompting approach developed in the next chapter.

Three strategies are particularly relevant to security analysis:

\textbf{Task decomposition} breaks a complex audit into smaller sub-tasks—``summarise the contract's assets and trust boundaries'', ``identify external calls and state changes'', ``check whether state updates precede external interactions.''  Each sub-task has narrower scope and clearer success criteria, and the decomposition naturally aligns with tool usage: static analysis can enumerate call sites while the LLM focuses on explaining why a pattern is risky.

\textbf{Chain-of-thought (CoT)} prompting~\cite{wei2022chain} elicits intermediate reasoning steps and improves performance on multi-step tasks.  In security settings, however, the goal is not free-form reasoning traces but \emph{checkable} reasoning: claims should be tied to specific code locations or retrieved evidence.  ReVul-CoT~\cite{chen2025revulcot} demonstrates this principle by guiding LLMs through structured step-by-step CVSS assessment grounded in retrieved vulnerability records.

\textbf{Few-shot learning} calibrates what ``good'' output looks like.  In auditing, examples are most valuable when they mirror the desired report structure (severity, impact, evidence, remediation) and when they demonstrate appropriate epistemic caution—preferring ``uncertain, needs further evidence'' over confident speculation.  This approach is compatible with retrieval: retrieved vulnerability reports become dynamic few-shot demonstrations tailored to the contract under analysis.


% ============================================================
\section{Embeddings}
\label{sec:code-models}
% ============================================================

General-purpose LLMs treat code as just another form of text, but models explicitly pre-trained or fine-tuned on source code develop richer representations of programming constructs.  These specialised models matter for smart contract analysis in two ways: they produce better \emph{embeddings} for retrieval and similarity search, and they achieve stronger performance on code understanding tasks.

\subsection{Code Embeddings}
\label{subsec:embeddings}

An \emph{embedding} is a fixed-dimensional vector representation of a code snippet, produced by passing the snippet through an encoder model and extracting the hidden state (typically via mean pooling or the \texttt{[CLS]} token).  Two code fragments with similar semantics should have embeddings that are close in vector space, enabling nearest-neighbour retrieval over large code corpora.

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: 2D t-SNE or UMAP projection of code embeddings, colour-coded 
% by vulnerability type, showing clustering behaviour.  Could use 
% CodeBERT embeddings of SmartBugs-Curated contracts.
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=0.7\textwidth]{images/embedding_space.pdf}
%     \caption{Projected embedding space of Solidity functions encoded by CodeBERT, 
%              coloured by vulnerability type.  Semantically similar vulnerability 
%              patterns cluster together, enabling retrieval-based detection.}
%     \label{fig:embedding-space}
% \end{figure}
% ─────────────────────────────────────────────────────────────

The quality of embeddings depends critically on the pre-training data and objective.  General text embeddings conflate semantically different code that happens to use similar natural-language identifiers; code-aware embeddings trained on programming-language corpora better capture structural and functional similarity.


\subsection{Encoder Models}
\label{subsec:encoder-models}

\textbf{CodeBERT}~\cite{feng2020codebert} was one of the first models to pre-train a BERT-style encoder on both natural language and source code across six programming languages.  It uses both masked language modelling and replaced-token detection on NL–PL pairs, learning alignments between code and its documentation.  CodeBERT embeddings have become a standard baseline for code search, clone detection, and vulnerability classification.

\textbf{GraphCodeBERT}~\cite{guo2021graphcodebert} extends CodeBERT by incorporating data flow graphs into the pre-training objective, explicitly modelling variable definition-use chains.  This structural awareness improves performance on tasks that require understanding data dependencies—precisely the kind of reasoning needed to trace the flow of tainted data in a smart contract.

For smart contract vulnerability detection specifically, several studies have used encoder models as feature extractors.  Lightning Cat~\cite{lightningcat2023} uses CodeBERT preprocessing to achieve F1~scores above 93\% on the SolidiFI benchmark.  A comprehensive benchmark study by Sendner et al.~\cite{sendner2025firetries} compared seven pre-trained language models—BERT, CodeBERT, GraphCodeBERT, DeBERTa, RoBERTa, DistilBERT, and Longformer—for multi-label vulnerability detection across approximately 18,000 Ethereum smart contracts.


\subsection{Encoder–Decoder and Seq2Seq Models}
\label{subsec:seq2seq}

\textbf{T5} (Text-to-Text Transfer Transformer)~\cite{raffel2020exploring} frames every NLP task as a text-to-text problem, enabling a single model architecture to handle classification, translation, summarisation, and generation.

\textbf{CodeT5}~\cite{wang2021codet5} adapts the T5 architecture for code, using an identifier-aware pre-training objective that masks and recovers code identifiers rather than random tokens.  Its successor, \textbf{CodeT5+}~\cite{wang2023codet5p}, scales the model and adds contrastive learning objectives.  BreachT5~\cite{breacht5_2024} demonstrated that fine-tuned CodeT5+ ensembles can perform multi-label SWC classification over large smart contract datasets, though the model's 512-token input limit constrains analysis of longer contracts.

These encoder–decoder models are particularly well-suited for tasks framed as sequence-to-sequence transformation: given vulnerable code, generate a description of the vulnerability; or given a natural-language specification, generate a formal property for verification.  PropertyGPT~\cite{liu2025propertygpt} exploits this capability by using RAG over human-written verification properties to generate new formal specifications, uncovering 12 zero-day vulnerabilities that earned \$8,256 in bug bounties.


% ============================================================
\section{LLMs in Smart Contract Auditing}
\label{sec:llm-auditing}
% ============================================================

The application of LLMs to smart contract security has evolved rapidly since 2023, with approaches spanning four broad categories: prompt-only and agentic pipelines, fine-tuned detection models, RAG-augmented frameworks, and hybrid systems that combine multiple strategies.

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: Timeline/taxonomy diagram showing the four paradigms 
% and key papers in each, arranged chronologically from 2023–2025.
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\textwidth]{images/llm_auditing_taxonomy.pdf}
%     \caption{Taxonomy of LLM-based smart contract auditing approaches (2023–2025), 
%              organised by primary strategy.  Hybrid approaches that combine multiple 
%              paradigms are increasingly common.}
%     \label{fig:llm-taxonomy}
% \end{figure}
% ─────────────────────────────────────────────────────────────


\subsection{Prompt-Only and Agentic Auditing Pipelines}
\label{subsec:prompt-only}

The simplest approach feeds smart contract source code directly into a general-purpose LLM with appropriate instructions.  Chen et al.~\cite{chen2024chatgpt} conducted a systematic evaluation of GPT-3.5 and GPT-4 on the SmartBugs-Curated benchmark and found high recall but poor precision, with roughly 4 out of 5 flagged issues being false positives (GPT-4 achieved 88.2\% recall but only 22.6\% precision).  Perhaps more concerning, 42\% of contracts showed unstable detection outcomes across repeated runs, highlighting the non-deterministic nature of LLM-based analysis.

More structured prompt-based approaches improve on this baseline.  \textbf{GPTLens}~\cite{hu2023gptlens} introduced an adversarial two-stage pipeline: a high-temperature ``Auditor'' agent generates vulnerability candidates, and a separate ``Critic'' agent filters false positives.  \textbf{GPTScan}~\cite{sun2024gptscan} combined GPT with static analysis for token contract auditing, achieving over 90\% precision and discovering 9~vulnerabilities missed by human auditors, at a cost of approximately \$0.01 per 1,000 lines of code.

\textbf{LLM-SmartAudit}~\cite{wei2024smartaudit} deployed multi-agent conversational frameworks with role specialisation across 6,454 contracts from Code4rena competitions.  The multi-agent design mirrors how human audit teams operate, with different agents responsible for different vulnerability categories.

These results collectively establish that general-purpose LLMs can identify security issues in smart contracts but lack the precision needed for production use without additional grounding mechanisms.

\subsection{Fine-Tuned Models for Smart Contract Vulnerability Detection}
\label{subsec:fine-tuned}

Fine-tuning domain-specific models on labelled vulnerability datasets produces substantially stronger results than prompting alone.

\textbf{iAudit}~\cite{ma2025iaudit} introduced a two-stage fine-tuning pipeline: a Detector model for binary vulnerability classification and a Reasoner model for generating human-readable explanations.  These are complemented by Ranker and Critic LLM agents that iteratively debate and refine the outputs, outperforming baselines including CodeBERT, GraphCodeBERT, CodeT5, and UniXcoder.

\textbf{Smart-LLaMA-DPO}~\cite{yu2025smartllama} applies three-stage training to LLaMA-3.1-8B: continual pre-training on smart contract code, supervised fine-tuning, then Direct Preference Optimisation using paired quality explanations.  The result surpasses GPT-4o (accuracy 58.91\%) and iAudit (accuracy 64.42\%) with improvements of +10.43\% in F1 and +7.87\% in accuracy over the previous state of the art.

Bu et al.~\cite{bu2025dapp} fine-tuned Llama3-8B on 4,998 real DApp contracts with full-parameter fine-tuning and random oversampling, reaching F1~=~0.83 and precision~0.97 for price manipulation vulnerabilities—up from F1~=~0.20 without fine-tuning.

\textbf{LLMBugScanner}~\cite{yuan2024llmbugscanner} takes an ensemble approach, combining multiple LoRA-fine-tuned models from the OpenCode leaderboard through weighted voting.  This reduces the impact of individual model weaknesses but introduces complexity in deployment.


\subsection{RAG-Augmented Detection Frameworks}
\label{subsec:rag-augmented}

Retrieval-Augmented Generation (RAG) addresses the fundamental limitation that LLMs cannot ``know'' about vulnerability patterns not present in their training data, and that their context windows may be insufficient for analysing entire protocols.  Several RAG frameworks have emerged for smart contract security.

\textbf{ParaVul}~\cite{huang2025paravul} represents the most architecturally sophisticated approach.  It runs a SLoRA-fine-tuned LLaMA-13B detector and a hybrid RAG detector (combining dense embedding retrieval with BM25 lexical matching) in parallel, fusing their outputs through a meta-learning gated verification module.  The system achieves F1 scores of 0.9398 (single-label) and 0.9330 (multi-label), outperforming both standalone fine-tuning and standalone retrieval.  A final stage generates vulnerability reports using chain-of-thought prompts fed to a cloud-based LLM.

% ── PLACEHOLDER ──────────────────────────────────────────────
% FIGURE: ParaVul architecture diagram — four stages:
% (1) SLoRA fine-tuned detector
% (2) Hybrid RAG detector (dense + BM25)
% (3) Meta-learning fusion module
% (4) CoT report generation
% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=0.9\textwidth]{images/paravul_architecture.pdf}
%     \caption{ParaVul architecture~\cite{huang2025paravul}.  A fine-tuned LLM path and a hybrid 
%              RAG path operate in parallel; their predictions are fused by a meta-learning gate 
%              before chain-of-thought report generation.}
%     \label{fig:paravul}
% \end{figure}
% ─────────────────────────────────────────────────────────────

\textbf{SmartLLM}~\cite{smartllm2025} combines RAG with fine-tuned LLaMA~3.1, integrating ERC documentation for domain context.  It achieves 100\% recall with 62.5\% precision (F1~=~76.9\%), demonstrating how retrieval of standard documentation can reduce false negatives.

\textbf{PropertyGPT}~\cite{liu2025propertygpt} applies RAG in a different direction: rather than retrieving vulnerable code examples, it retrieves human-written formal verification properties from Certora audit reports and uses them to guide LLM-based property generation.  This yielded 80\% recall against ground-truth properties and uncovered 12~zero-day vulnerabilities.

\textbf{SmartGuard}~\cite{smartguard2025} retrieves semantically similar code snippets to generate chain-of-thought reasoning chains, achieving recall of 95.06\% and F1 of 94.95\% on the SolidiFI benchmark.

The most comprehensive framework is \textbf{LLM-BSCVM}~\cite{llmbscvm2025}, which implements a full vulnerability management lifecycle using a ``Decompose-Retrieve-Generate'' pipeline with multi-agent collaboration and LoRA-fine-tuned CodeLlama-13B, achieving 91\% accuracy with a 5.1\% false positive rate.

While not targeting smart contracts specifically, \textbf{ReVul-CoT}~\cite{chen2025revulcot} demonstrates the RAG+CoT paradigm's effectiveness for general software vulnerability severity assessment.  Using retrieval from NVD and CWE databases combined with structured chain-of-thought reasoning, it achieved 87.50\% accuracy and 83.75\% Macro-F1 on 12,070 vulnerability records—improvements exceeding 10 percentage points over all baselines.  Its architecture provides a transferable blueprint for smart contract severity assessment.

% ── PLACEHOLDER ──────────────────────────────────────────────
% TABLE: Comparison of LLM-based smart contract auditing approaches.
% Columns: Method | Approach | Base Model | Key Metric | Benchmark
% Rows: GPTScan, iAudit, Smart-LLaMA-DPO, ParaVul, SmartGuard, LLM-BSCVM
% \begin{table}[!htbp]
%     \centering
%     \caption{Comparison of LLM-based smart contract vulnerability detection approaches.}
%     \label{tab:llm-comparison}
%     \begin{tabular}{lllll}
%     \toprule
%     \textbf{Method} & \textbf{Approach} & \textbf{Base Model} & \textbf{Best F1} & \textbf{Benchmark} \\
%     \midrule
%     GPTScan       & Prompt + SA   & GPT-4        & >0.90 (precision) & Token contracts \\
%     iAudit        & Fine-tune     & LLaMA        & —                  & Custom \\
%     Smart-LLaMA-DPO & FT + DPO   & LLaMA-3.1-8B & +10.43\% over SOTA & Custom \\
%     ParaVul       & FT + RAG      & LLaMA-13B    & 0.9398             & Custom \\
%     SmartGuard    & RAG + CoT     & —            & 0.9495             & SolidiFI \\
%     LLM-BSCVM     & RAG + agents  & CodeLlama-13B & 0.91 (acc)        & Custom \\
%     \bottomrule
%     \end{tabular}
% \end{table}
% ─────────────────────────────────────────────────────────────


% ============================================================
\section{Challenges and Limitations}
\label{sec:llm-challenges}
% ============================================================

Despite rapid progress, LLM-based smart contract auditing faces fundamental challenges that constrain its reliability in production settings.

\subsection*{Hallucinations}
\label{subsec:hallucinations}

LLMs can produce plausible-sounding but factually incorrect outputs—a phenomenon termed \emph{hallucination}.  In code generation, this manifests as references to non-existent libraries, fabricated API calls, and invented vulnerability reports.  Spracklen et al.~\cite{spracklen2025package} tested 16~LLMs generating 576,000 code samples and found that 19.7\% of the 2.23~million referenced packages were hallucinated (non-existent), creating a direct supply-chain attack vector.

For security specifically, the consequences are severe.  Pearce et al.~\cite{pearce2022asleep} found that approximately 40\% of GitHub Copilot's code completions contained vulnerabilities.  Perry et al.~\cite{perry2023users} demonstrated that users with AI coding assistant access wrote significantly less secure code while being more confident in its correctness—a dangerous automation bias.

In the smart contract domain, Chen et al.~\cite{chen2024chatgpt} identified several hallucination patterns: ``Protected Mechanism Bias'' (the model assumes protective code exists when it does not), ``Development Intent Bias'' (the model assumes developers followed best practices), and ``Lack of Understanding of Actual Meaning'' of Solidity-specific constructs like \texttt{msg.value}.

The primary mitigation is to require \emph{grounded evidence} for every finding.  Each reported vulnerability should reference specific code locations, static analysis outputs, or retrieved documentation rather than relying on the model's ``intuition'' alone.  RAG-based systems consistently reduce hallucination rates: LLM-BSCVM reduced false positives from 7.2\% to 5.1\% through retrieval-grounded multi-agent collaboration~\cite{llmbscvm2025}.


\subsection*{Context Window Limitations}
\label{subsec:context-window-limits}

Even with context windows reaching hundreds of thousands of tokens, real smart contract systems can exceed what is reasonable to include in a single prompt.  Imported libraries, interface definitions, deployment configurations, and cross-contract dependencies all contribute to the token budget.  Moreover, models have a fixed training cutoff: new vulnerability classes and evolving best practices emerge continuously but are absent from the model's parametric knowledge.

RAG partially addresses both issues by retrieving up-to-date, task-relevant information at inference time and by focusing the prompt on high-signal content~\cite{lewis2020retrieval}.  The remaining challenge is retrieval precision: irrelevant chunks can overwhelm the model and degrade output quality.  ReVul-CoT's ablation studies confirmed that retrieval Top-$k$ requires careful tuning to balance contextual richness against noise~\cite{chen2025revulcot}.


\subsection*{Security}
\label{subsec:security}

Security audits demand reproducible, traceable outputs.  Purely generative answers are difficult to verify after the fact, and identical prompts may yield different results across runs.  Chen et al.~\cite{chen2024chatgpt} found 42\% of smart contracts showed unstable detection outcomes across repeated GPT-4 evaluations.

Tool-augmented approaches improve reproducibility by logging which code artifacts, retrieved documents, and tool outputs contributed to each finding.  This creates an audit trail that separates verifiable computations (static analysis queries, retrieval results) from probabilistic interpretation (the LLM's summary and explanation).

When LLM agents can call external tools, additional safety concerns arise.  Prompt injection in retrieved documents could manipulate the agent's behaviour, and unrestricted tool access could enable unintended actions.  For our setting, we mitigate these risks by restricting the agent's tool surface to read-only analysis and retrieval primitives, and by treating all retrieved text as untrusted input that must not override analysis policies~\cite{greshake2023youve}.

This chapter traced the mathematical foundations of sequence modeling through the transformer architecture and its modern extensions, arriving at a clear picture of where LLMs excel and where they fall short for smart contract auditing.

The transformer's self-attention mechanism gives LLMs the ability to relate distant code elements directly—a critical capability for tracing data flows and identifying cross-function vulnerabilities.

After having the overview about Ethereum, Code Analysis and LLMs, we can move to framework Wake, which comnined all of this for security purposes.

\chapter{The Wake Framework}
\label{chap:wake}

This chapter provides a fundamental overview of Wake framework. It focuses on its internal model and analysis workflow. After it, the separate module with AI integration is described with findings of limitations. [TODO]

\section{Overview}
\label{sec:wake-overview}

Wake is an open source Python-based development, testing, and security analysis framework specifically designed for Solidity smart contracts~\cite{wake-docs} [TODO how to correctly cite this docs]. Developed by Ackee Blockchain Security\footnote{\url{https://ackee.xyz/}}, Wake addresses the critical need for comprehensive tooling in the blockchain security ecosystem. 

The framework provides several core capabilities:

\begin{itemize}
    \item \textbf{Testing Framework}: Built on top of \texttt{pytest}~\cite{pytest}, Wake enables developers to write unit tests and integration tests for smart contracts using Python's familiar testing idioms.

    \item \textbf{Property-Based Fuzzer}: Wake includes a sophisticated fuzzer supporting both property-based and manually-guided fuzzing strategies to discover edge cases and vulnerabilities through automated input generation.

    \item \textbf{Vulnerability Detectors}: The framework ships with built-in detectors for common vulnerability patterns such as reentrancy, integer overflows, and logic flaws. These detectors are designed with a low false-positive philosophy to minimize manual investigation overhead during audits.

    \item \textbf{Printers}: Information extraction tools that generate structured outputs about contract properties, including control flow graphs, inheritance hierarchies, and data dependencies.

    \item \textbf{Development Tools}: Wake integrates with modern development workflows through a Language Server Protocol (LSP) implementation and a Visual Studio Code extension called ``Tools for Solidity''~\cite{tools-for-solidity}, providing real-time feedback on vulnerabilities and code quality.

    \item \textbf{Deployment and Interaction}: Support for mainnet interactions and contract deployments, enabling seamless transition from testing to production.
\end{itemize}

Wake has been actively used by Ackee Blockchain Security in professional smart contract audits, where it has helped discover numerous high and critical severity vulnerabilities in protocols such as IPOR Protocol\footnote{\url{https://www.ipor.io/}}, PWN Protocol\footnote{\url{https://pwn.xyz/}}, Brahma Console\footnote{\url{https://console.brahma.fi/}}, and Lido Community Staking Module\footnote{\url{https://csm.lido.fi/}} \cite{wake-docs}.


\section{Internal Model}
\label{sec:wake-internal-model}

Wake constructs a rich internal representation of Solidity smart contracts that serves as the foundation for all analysis capabilities. Because of Wake build base on static analysis, all its components were described in Section \ref{sec:static-analysis}.

\subsubsection*{Intermediate Representation}
\label{subsubsec:wake-ir}

At the core of Wake's analysis capabilities lies a typed intermediate representation (IR) derived from the Solidity compiler's Abstract Syntax Tree (AST). The IR provides a structured view of the source code, representing all language constructs. The IR preserves type information and cross-references between declarations and their usages, enabling precise semantic analysis. Each IR node maintains references to its parent and children, facilitating traversal in any direction. Wake's IR is fully typed using Python's type system, ensuring type safety during analysis development.


\subsubsection*{Control Flow Graph}
\label{subsubsec:wake-cfg}

Wake constructs CFGs for functions and modifiers, representing the possible execution paths through the code. It provides utility functions for reachability analysis, such as determining whether the start node is reachable from a given position (backward reachability), or whether the success/revert end nodes are reachable from a statement (forward reachability). These primitives are essential for detecting issues like dead code or functions that always revert.

\subsubsection*{Data Dependency Graph}
\label{subsubsec:wake-ddg}

The DDG is one of Wake's most sophisticated analysis structures, tracking how data flows through the contract. It automatically expands composite types (structs, arrays, mappings) to track data flow at the member/element level. For example, when a struct is assigned, the DDG creates edges not only for the struct itself but also for each of its members recursively.

\section{Analysis Instruments}
\label{sec:wake-analysis}

Building upon the internal model, Wake provides a comprehensive infrastructure for implementing various analysis techniques.

\subsubsection*{Detectors}
\label{subsubsec:wake-detectors}

Wake's static analysis framework enables the implementation of custom vulnerability detectors. It already covers patterns like reentrancy, unsafe ERC-20 call, unused constructions and many others\footnote{\url{https://ackee.xyz/wake/docs/latest/static-analysis/using-detectors/}}. Each detector is a Python class that:

\begin{enumerate}
    \item Receives access to the compiled IR and associated graphs (CFG, DDG).
    \item Traverses relevant code structures to identify potential issues.
    \item Reports findings with precise source locations and severity classifications.
\end{enumerate}

\subsubsection*{Fuzz Testing}
\label{subsubsec:wake-fuzzing}

Complementing static analysis, Wake provides robust support for dynamic testing and fuzzing:

\begin{itemize}
    \item \textbf{pytest Integration}: Tests are written as standard Python functions using pytest fixtures and assertions, lowering the barrier for developers familiar with Python testing.

    \item \textbf{Property-Based Fuzzing}: Wake's fuzzer generates diverse inputs to test invariants and properties, automatically exploring edge cases that manual testing might miss.

    \item \textbf{Stateful Fuzzing}: Support for fuzzing that maintains state across operations, essential for testing complex DeFi protocols with multi-step interactions.

    \item \textbf{Shrinking}: When the fuzzer finds a failing input, it attempts to minimize the input to the smallest case that still reproduces the failure, simplifying debugging.
\end{itemize}

Wake has been used to discover critical vulnerabilities through fuzzing in production protocols. The framework's test collection ``Awesome Wake Tests''~\cite{awesome-wake-tests} provides reference implementations demonstrating effective fuzzing strategies.


\subsubsection*{Printers}
\label{subsubsec:wake-printers}

Wake includes auxiliary tools that support development and audit workflows:

\begin{itemize}
    \item \textbf{Printers}: Extract and visualize structural information from contracts:
    \begin{itemize}
        \item Contract cross-reference graphs showing relationships between contracts
        \item Data dependency graph visualization using Graphviz
        \item Contract size estimation for deployment gas optimization
        \item Contract summaries and function signature extraction
        \item C3 linearization visualization for inheritance analysis
    \end{itemize}

    \item \textbf{Language Server Protocol (LSP)}: Real-time analysis integration with editors, providing:
    \begin{itemize}
        \item On-the-fly vulnerability detection
        \item Code navigation and go-to-definition
        \item Hover information with type details
        \item Variable DDG visualization within the editor
    \end{itemize}

    \item \textbf{Compiler Management}: Built-in \texttt{solc} version management for reproducible builds across different Solidity versions.

    \item \textbf{Code Flattening}: Utility for combining multi-file contracts into a single file for verification on block explorers.
\end{itemize}


\section{Wake-AI}
\label{sec:wake-ai}

With fast developing of tehcnologies, growing LLM capabilities and often their usage in practice, as we were able notice in Section \ref{sec:}, LLMs are integrated into Wake as special separate tool aimed to comprehensive AI audit of smart contracts. Unfortunateylly, challneges of static analysis described above, restricted a lo of spce and other rtypes of vulnerabilities. So there is time, when huge language models come to help auditors with security analysis. 

\subsection{Architecture}
\label{subsec:wake-ai-architecture}

Wake-AI extends the Wake framework with artificial intelligence capabilities for automated security auditing. It implements a multi-stage workflow architecture where each stage performs a specific analysis task. The system orchestrates AI models through structured sessions:

\begin{itemize}
    \item \textbf{Session Management}: Wake-AI supports multiple AI backends, including Claude (via MCP---Model Context Protocol) and OpenAI Codex models. Sessions maintain conversation context and can be forked for parallel processing.

    \item \textbf{MCP Integration}: Wake exposes its analysis capabilities as MCP tools, allowing AI models to query the IR, retrieve function signatures, access CFG information, and invoke static analysis detectors during their reasoning process.

    \item \textbf{Working Directory}: Each audit maintains a structured working directory containing intermediate results, allowing workflow resumption and result inspection.

    \item \textbf{Progress Tracking}: The framework provides real-time progress updates and token usage tracking for cost management.

    \item Prompt-Based Reasoning and Validation
\end{itemize}


\subsection{Limitations}
\label{subsec:wake-ai-limitations}

Despite its capabilities, Wake-AI faces several limitations:

\begin{itemize}
    \item \textbf{Context Window Constraints}: LLMs have limited context windows, restricting the amount of code and analysis data that can be processed simultaneously. Large codebases may require chunking strategies that could miss cross-file vulnerabilities.

    \item \textbf{Hallucination Risk}: AI models may generate plausible-sounding but incorrect vulnerability reports. The triage phase mitigates this through evidence requirements, but some false positives may persist.

    \item \textbf{Determinism}: AI model outputs are inherently non-deterministic, potentially producing different findings on repeated runs of the same codebase.

    \item \textbf{Knowledge Cutoff}: Models may lack awareness of recently discovered vulnerability patterns or new Solidity language features introduced after their training data cutoff.

    \item \textbf{Limited Tool Access}: While MCP integration provides access to Wake's analysis tools, the AI cannot execute arbitrary code or perform dynamic testing during analysis. Complex vulnerabilities requiring runtime behavior observation may be missed.
\end{itemize}

Some of these limitations merit attention and can be addressed through alternative approaches. Others, such as hallucination risk and non-determinism, cannot be fully resolved due to the inherent nature of LLMs. This thesis focuses on one of the most critical limitations: knowledge cutoff. The following chapter presents a proposed solution designed to increase the detection of genuine security issues while reducing false positives. This is achieved by providing the LLM with similar historical issues, enabling it to make more informed judgments about vulnerabilities.


\chapter{Proposed Methodology}
% THIS is your main “design contribution” chapter.
\section{Design Goals}


\section{Retrieval augmented generation systen}

A recent study by Lewis et al. [2020] investigates advancements in RAG models. They detail the architecture and key strategies employed in RAG, which
aim to leverage the strengths of LLMs while simultaneously mitigating their
limitations. 

he RAG framework comprises of two primary components: a retriever in
Equation 2.1 and a generator in Equation 2.2, parameterized by η and θ respectively. The retriever retrieves (topk truncated) distributions over text passages given an input query x, while the generator generates the next token
based on the context of preceding tokens, the input sequence, and a retrieved
passage.
pη(z|x) (2.1)
• η: Non-parametric retriever.
• x: Sequence given by user.
• z: Text passages to retrieve.
pθ(yi
|x, z, y1:i−1) (2.2)
• θ: Parametric generator.
• yi
: Target sequence to generate.
• y1:i−1: Sequences previously generated.


% Cite RAG paper for concept framing. :contentReference[oaicite:21]{index=21}
\subsection{Query Generation}
% How you create retrieval queries: from detectors, IR features, function summaries, etc.
\subsection{Re-ranking}
% How you select top-k, de-duplicate, and compress into prompt context.


% Goals: groundedness, audit usefulness, token efficiency, modularity, reproducibility.
\section{System Architecture Overview}
% Diagram: Wake-AI steps + retrieval module + KB + MCP server + LLM.
% Cite MCP intro/spec. :contentReference[oaicite:19]{index=19}
\subsection{High-Level Workflow}

\section{Knowledge Base}
Describe solodit, that it will be taken from here, placed their all data with labels, metadata, crossing and mainly embed by summaries with normalization, Also there is a part with code + private reports from ackee audits

\subsection{Indexing and Embeddings}
% How documents are chunked + embedded for retrieval.
TODO

\section{Model context protocol integration}
\subsection{Endpoints and Contracts}
% Define each endpoint (search patterns, fetch details, get examples, etc.) with expected inputs/outputs.
\subsubsection*{Security considerations}
% Timeouts, empty results, injection resistance, deterministic logging.

\section{Prompt engineering}
\subsection{TODO}

\section{Chapter Summary and Transition to Implementation}
% 5–8 lines: design choices -> now show how it’s implemented inside Wake-AI.

\chapter{Evaluation}

\section{Dataset}

% Goal: show it works and understand when/why.
\section{Evaluation Questions}
% RQ1: Does RAG reduce hallucinations/false positives? RQ2: Does it improve coverage? RQ3: Cost/latency tradeoffs?
\section{Experimental Setup}
\subsection{Benchmarks and Datasets}
% Real vulnerable contracts + (optional) synthetic cases to test each pipeline component.
\subsection{Baselines}
% Wake-AI (prompt-only), Wake detectors, and Slither as external baseline. :contentReference[oaicite:22]{index=22}
\subsection{Metrics}
% Precision/recall per vulnerability class; “evidence correctness”; runtime/token cost.

\section{Experiments}
\subsection{Retrieval Quality (Component Test)}
% Top-k hit rate / qualitative relevance checks of retrieved patterns.
\subsection{End-to-End Vulnerability Detection}
% Compare baseline vs RAG-augmented on same contracts.
\subsection{Ablation Study}
% Remove reranking / remove audit KB / remove detector-seeded queries to show what matters.
\subsection{Qualitative Case Studies and Error Analysis}
% 2–3 focused cases: success, failure, “helped explanation but not detection,” etc.

\section{Threats to Validity}
% Dataset bias, label quality, prompt sensitivity, reproducibility, and generalization.
\section{Summary and Transition to Conclusion}
% 5–8 lines: what improved, what didn’t, and why.

\chapter{Conclusion}
\section{Summary of Contributions}
% One tight list: RAG+MCP integration, KB design, Wake-AI extension, empirical findings.
\section{Limitations}
% Where it fails: KB gaps, retrieval noise, complex protocol logic, environment assumptions.
\section{Future Work}
% Strong future directions: tighter static/IR-guided retrieval, symbolic checks, richer audit KB, standardized benchmarks.